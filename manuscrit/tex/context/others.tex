\section{Modèles de programmation à base de tâches}\label{sec:context:others}

Il existe de nombreux modèles de programmation à base de tâches, certaines fonctionnalités diffèrent, mais les concepts de base restent les même, et seront détaillés ci dessous.

\subsection{L'unité de base : la tâche}

Une tâche peut être vue comme la plus petite quantité de travail séquentiel exécutable sur un processeur.
En pratique c'est une section de code bien définie du programme, et cela peut être une simple instruction, comme une fonction très complexe.

\subsection{Moyens de synchronisation}

Lorsqu'on parle de programmation parallèle, il faut bien évidemment parler de synchronisation.
Les différentes tâches définies par l'utilisateur vont être exécutées en parallèle sur la machine, mais dans beaucoup de cas certaines tâches doivent attendre la complétion d'une ou plusieurs tâches avant de pouvoir commencer à être exécutée.

Il y a deux grand types de synchronisations pour la programmation à base de tâche~:

\begin{itemize}
  \item la synchronisation dans le thread courant : le thread se bloque sur un point de synchronisation, et attend que l'ensemble des tâches qu'il a créé ait été exécutées avant de reprendre son exécution. Dans l'exemple du listing~\ref{lst:context:task-wait}, exprimé en OpenMP, la tâche C sera garantie d'être exécutée \textbf{après} les tâches A et B.
  \item ajouter des dépendances de données, induisant un ordre sur l'exécution des tâches. Dans le listing~\ref{lst:context:task-dep}, la tâche C sera également garantie d'être exécutée \textbf{après} les tâches A et B, car elle consomme des données que A et B produisent.
\end{itemize}

\begin{lstlisting}[caption=Synchronisation dans le thread courant (OpenMP),label=lst:context:task-wait]
void foo() {
  #pragma omp task
  A();
  #pragma omp task
  B();
  #pragma omp taskwait
  #pragma omp task
  C();
}
\end{lstlisting}

\begin{lstlisting}[caption=Synchronisation via des dépendances (OpenMP),label=lst:context:task-dep]
void foo() {
  int a;
  int b;
  #pragma omp task depend(out: a)
  A(&a);
  #pragma omp task depend(out: b)
  B(&b);
  #pragma omp task depend(in: a, b)
  C(a, b);
}
\end{lstlisting}

GRAPHE : 2.2.2 mini schéma dataflow du graphe correspondant au programme écrit.

Les deux ont des avantages et des inconvénients : la synchronisation dans le thread courant représente très peu d'overhead lors de l'exécution, mais si le travail est légèrement déséquilibré, certains threads pourraient rester inactifs alors que des tâches pourraient être exécutées.
Les dépendances induisent un coût de calcul des tâches prêtes lors de l'exécution, mais maximise l'utilisation des ressources.

En dehors de ces mécanismes de base, certains autres moyen de synchronisations peuvent être également utilisés pour garantir un ordre ou la correction du programme.
On peut mentionner les sections critiques : elles marquent une zone du programme parallèle que seul un thread peut exécuter à la fois.


\subsection{Quantité de travail et granularité}

Dans ce type de modèles de programmation, la clé pour maximiser l'utilisation des ressources et réduire l'overhead du support exécutif est de trouver le bon \emph{grain} de tâche.

Les tâches doivent être suffisamment petites pour proposer le maximum de parallélisme, mais pas trop pour ne pas surcharger le support exécutif.

Le listing~\ref{lst:context:tbb} illustre ce concept en TBB.
Le code exposé calcule le nième nombre de la suite de Fibonacci, en utilisant une implémentation à base de fonction récursive.
Sans introduire de cutoff, le nombre de tâches créée serait exponentiel, et introduirait un surcout de gestion des tâches à l'exécution qui détruirait le gain de performance apporté par le parallélisme exposé.

Le choix du grain pour une tâche dépend entièrement de l'application, et reste à l'appréciation du programmeur.


\subsection{Quelques exemples de modèles de programmation}

Plusieurs modèles de programmation populaires proposent d'exprimer du parallélisme à base de tâches.
Les trois les plus populaires sont sûrement Cilk, TBB, et OpenMP.

Les listings~\ref{lst:context:cilk},~\ref{lst:context:tbb}, et ~\ref{lst:context:openmp} donnent une comparaison de l'expression du même exemple simple, le calcul du nième nombre de la suite de Fibonacci.

\subsubsection{Cilk}

Cilk~\cite{cilk5} est un modèle de programmation basé sur C/C++, et proposant des fonctionnalités communes aux modèles de programmation : parallélisme de tâches, de boucles, et vectorisation.
Cilk propose également une extension de la notation de tableau, ayant pour but de faciliter la vectorisation automatique par le compilateur.


\begin{lstlisting}[language=c++,caption=Fibonacci exprimé en Cilk,label=lst:context:cilk,basicstyle=\scriptsize]
int fib(int n) {
  if (n < 2)
    return n;
  int x = cilk_spawn fib(n-1);
  int y = fib(n-2);
  cilk_sync;
  return x + y;
}
\end{lstlisting}


\subsubsection{Threading Building Block}

Threading Building Block (TBB)~\cite{Reinders2007} est un modèle de programmation développé par Intel comme une librairie C++.

C'est un modèle de programmation à base de tâches, mais permettant d'exprimer les constructions de parallélismes standard comme les boucles. Il propose également des constructions plus spécifiques, telles que les opérations atomiques et les sections critiques.

La bibliothèque propose également un ensemble de structures de données à accès concurrent (listes, tables de hachage), ainsi que des allocateurs mémoires.

\begin{lstlisting}[language=c++,caption=Fibonacci exprimé en TBB,label=lst:context:tbb,basicstyle=\scriptsize]
// Code séquentiel
long SerialFib(long n) {
  if (n<2)
    return n;
  else
    return SerialFib(n-1) + SerialFib(n-2);
}

// Tâche parallèle
class FibTask: public task {
public:
  const long n;
  long* const sum;
  FibTask(long n_,long* sum_) : n(n_), sum(sum_) {}
  // Surcharge de la fonction virtuelle task::execute
  task* execute() {
    if (n < CutOff) {
      *sum = SerialFib(n);
    } else {
      long x, y;
      FibTask& a = *new(allocate_child()) FibTask(n-1,&x);
      FibTask& b = *new(allocate_child()) FibTask(n-2,&y);
      // Set ref_count to 'two children plus one for the wait".
      set_ref_count(3);
      // Start b running.
      spawn(b);
      // Start a running and wait for all children (a and b).
      spawn_and_wait_for_all(a);
      // Do the sum
      *sum = x+y;
    }
    return nullptr;
  }
};

// Code générant la première tâche parallèle
long ParallelFib( long n ) {
  long sum;
  FibTask& a = *new(task::allocate_root()) FibTask(n, &sum);
  task::spawn_root_and_wait(a);
  return sum;
}
\end{lstlisting}

\subsubsection{OpenMP}

OpenMP~\cite{openmp45} est un modèle de programmation supportant le C/C++ et Fortran.

Il s'utilise à travers des directives de compilation ainsi qu'une API, et propose lui aussi les constructions classiques : boucles, tâche, et autres éléments facilitant la programmation parallèle.

Le standard d'application de nos idées pour cette thèse étant OpenMP, une description détaillée des fonctionnalités et de ses spécificités est faite dans la section~\ref{sec:context:openmp}.

\begin{lstlisting}[language=c++,caption=Fibonacci exprimé en OpenMP,label=lst:context:openmp,basicstyle=\scriptsize]
int fib(int n) {
  if (n < 2)
    return n;
#pragma omp task
  int x = fib(n-1);
  int y = fib(n-2);
#pragma omp taskwait
  return x + y;
}
\end{lstlisting}

\subsection*{Conclusion}

Peu importe le modèle de programmation, car au final dans tous ces modèles l'application est décrite par un graphe de tâches direct et acyclique (DAG).

L'étape suivante consiste à exécuter ce graphe sur la machine, et pour cela le support exécutif peut se reposer sur un ensemble important de techniques d'ordonnancement. 



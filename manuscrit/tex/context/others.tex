\section{Modèles de programmation à base de tâches}\label{sec:context:others}

Il existe de nombreux modèles de programmation à base de tâches, certaines fonctionnalités diffèrent, mais les concepts de base restent les même, et seront détaillés ci dessous.

\subsection{L'unité de base : la tâche}

Une tâche peut être vue comme la plus petite quantité de travail séquentiel exécutable sur un processeur.
En pratique c'est une section de code bien définie du programme, et cela peut être une simple instruction, comme une fonction très complexe.

Dans certains supports exécutifs, tel que StarPU, certaines extensions permettent d'adapter cette notion d'unité de base en agglomérant, ou découpant, des tâches séquentielles.

\subsection{Moyens de synchronisation}

Lorsqu'on parle de programmation parallèle, il faut bien évidemment parler de synchronisation.
Les différentes tâches définies par l'utilisateur vont être exécutées en parallèle sur la machine, mais dans beaucoup de cas certaines tâches doivent attendre la complétion d'une ou plusieurs tâches avant de pouvoir commencer à être exécutée.

Il y a deux grand types de synchronisations pour la programmation à base de tâche~:

\begin{itemize}
  \item la synchronisation dans le thread courant : le thread se bloque sur un point de synchronisation, et attend que l'ensemble des tâches qu'il a créé ait été exécuté avant de reprendre son exécution. Dans l'exemple du listing~\ref{lst:context:task-wait}, exprimé en OpenMP, la tâche C sera garantie d'être exécutée \textbf{après} les tâches A et B.
  \item ajouter des dépendances de données, induisant un ordre sur l'exécution des tâches. Dans le listing~\ref{lst:context:task-dep}, la tâche C sera également garantie d'être exécutée \textbf{après} les tâches A et B, car elle consomme des données que A et B produisent.
\end{itemize}

\begin{lstlisting}[caption=Synchronisation dans le thread courant (OpenMP),label=lst:context:task-wait]
void foo() {
  #pragma omp task
  A();
  #pragma omp task
  B();
  #pragma omp taskwait
  #pragma omp task
  C();
}
\end{lstlisting}

\begin{lstlisting}[caption=Synchronisation via des dépendances (OpenMP),label=lst:context:task-dep]
void foo() {
  int a;
  int b;
  #pragma omp task depend(out: a)
  A(&a);
  #pragma omp task depend(out: b)
  B(&b);
  #pragma omp task depend(in: a, b)
  C(a, b);
}
\end{lstlisting}

GRAPHE : 2.2.2 mini schéma dataflow du graphe correspondant au programme écrit.

Les deux ont des avantages et des inconvénients : la synchronisation dans le thread courant représente très peu d'overhead lors de l'exécution, mais si le travail est légèrement déséquilibré, certains threads pourraient rester inactifs alors que des tâches pourraient être exécutées.
Les dépendances induisent un coût de calcul des tâches prêtes lors de l'exécution, mais maximise l'utilisation des ressources.

En dehors de ces mécanismes de base, d'autres moyen de synchronisations peuvent être également utilisés pour garantir un ordre ou la correction du programme.
On peut mentionner les sections critiques, les mutex, les moniteurs, ou encore les sémaphores : l'ensemble de ces mécanismes à pour but de délimiter une zone du programme parallèle que seul un thread peut exécuter à la fois.


\subsection{Quantité de travail et granularité}

\begin{todo}
  Parler du coût naturel d'une tâche, de la vie de la création à la fin de l'exécution.
  (+ parler outlining, création manuelle)

  Piège ?
  - intrusif (exemples !)
  - granularité (cf courbe starpu)

  Exemple 
\end{todo}

Dans ce type de modèles de programmation, la clé pour maximiser l'utilisation des ressources est de réduire l'overhead du support exécutif par rapport au calcul en trouvant le bon \emph{grain} de tâche.

Il y a donc un compromis à trouver entre le degré de parallélisme et les performances : les tâches doivent être suffisamment petites pour proposer le maximum de parallélisme, mais pas trop pour ne pas surcharger le support exécutif.

Le listing~\ref{lst:context:cilk} illustre ce concept en Cilk.
Le code exposé calcule le nième nombre de la suite de Fibonacci, en utilisant une implémentation à base de fonction récursive.
La création de tâche ne porte que sur l'une des deux branches récursives, limitant ainsi le nombre de tâches créées et donc le surcoût de gestion des tâches à l'exécution.

Le choix du grain pour une tâche dépend entièrement de l'application, et reste à l'appréciation du programmeur.


\subsection{Quelques exemples de modèles de programmation}

Plusieurs modèles de programmation populaires proposent d'exprimer du parallélisme à base de tâches.
Les trois les plus populaires sont sûrement Cilk, TBB, et OpenMP.

Les listings~\ref{lst:context:cilk},~\ref{lst:context:tbb}, et ~\ref{lst:context:openmp} donnent une comparaison de l'expression du même exemple simple, le calcul du nième nombre de la suite de Fibonacci.

\subsubsection{Cilk}

Cilk~\cite{cilk5} est un modèle de programmation basé sur C.
Il introduit principalement deux nouveaux mots clés : |cilk_spawn| et |cilk_sync|, pour, respectivement, exposer du parallélisme et introduire un point de synchronisation.
Le mot clé |cilk_spawn| vient précéder un appel de fonction pour indiquer que la fonction peut s'exécuter en parallèle. Cela en fait donc un modèle de programmation à base de tâches.
Cilk propose également une extension de la notation de tableau, ayant pour but de faciliter la vectorisation automatique par le compilateur.


\begin{lstlisting}[language=c++,caption=Fibonacci exprimé en Cilk,label=lst:context:cilk,basicstyle=\small]
int fib(int n) {
  if (n < 2)
    return n;
  int x = cilk_spawn fib(n-1);
  int y = fib(n-2);
  cilk_sync;
  return x + y;
}
\end{lstlisting}


\subsubsection{Threading Building Block}

Threading Building Block (TBB)~\cite{Reinders2007} est un modèle de programmation développé par Intel comme une bibliothèque C++.

Elle propose différentes fonction pour que le programmeur puisse exprimer du parallélisme, dont notamment :
\begin{itemize}
  \item La fonction template |parallel_for|, s'appliquant sur une boucle et prenant en paramètre une fonction utilisateur.
    La bibliothèque découpe automatiquement l'espace d'itération en groupes d'itérations et envoie un itérateur C++ à la fonction utilisateur pour son traitement.
  \item Un ensemble de fonction pour accéder à l'ordonnanceur de tâches de la bibliothèque.
\end{itemize}

La bibliothèque propose également un ensemble de structures de données à accès concurrent (listes, tables de hachage), ainsi que des allocateurs mémoires.

\begin{lstlisting}[language=c++,caption=Fibonacci exprimé en TBB,label=lst:context:tbb,basicstyle=\small]
#include "tbb/task_group.h"
using namespace tbb;

int Fib(int n) {
  if( n<2 ) {
    return n;
  } else {
    int x, y;
    task_group g;
    g.run([&]{x=Fib(n-1);}); // création d'une tâche
    g.run([&]{y=Fib(n-2);}); // création d'une autre tâche
    g.wait();                // synchronisation
    return x+y;
  }
}
\end{lstlisting}

\subsubsection{OpenMP}

OpenMP~\cite{openmp45} est un modèle de programmation supportant le C/C++ et Fortran.
Il s'utilise à travers des directives de compilation ainsi qu'une API, et propose lui aussi les constructions classiques : boucles, tâche, et autres éléments facilitant la programmation parallèle.

Originellement OpenMP ne proposait que du parallélisme de boucle, le concept de tâches n'a été introduit que plus tard avec OpenMP~3.0, et le concept de dépendances de données entre tâches a été introduit encore plus tard avec la version~4.0.

Le standard d'application de nos idées pour cette thèse étant OpenMP, une description détaillée des fonctionnalités et de ses spécificités est faite dans la section~\ref{sec:context:openmp}.

\begin{lstlisting}[language=c++,caption=Fibonacci exprimé en OpenMP,label=lst:context:openmp,basicstyle=\small]
int fib(int n) {
  if (n < 2)
    return n;
#pragma omp task
  int x = fib(n-1);
  int y = fib(n-2);
#pragma omp taskwait
  return x + y;
}
\end{lstlisting}

\subsection*{Conclusion}

Peu importe le modèle de programmation, car au final dans tous ces modèles l'application est décrite par un graphe de tâches direct et acyclique (DAG).

L'étape suivante consiste à exécuter ce graphe sur la machine, et pour cela le support exécutif peut se reposer sur un ensemble important de techniques d'ordonnancement. 



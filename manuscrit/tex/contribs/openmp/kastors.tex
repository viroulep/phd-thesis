\section{Utilisation des machines NUMA à travers OpenMP}

\subsection{Constructions, clauses, et outils utilisés}


\subsection{Une suite de benchmark utilisant les dépendances de données d'OpenMP : KASTORS}

\begin{todo}
\cite{Virouleau2014}, Evaluation of OpenMP dependent tasks with the KASTORS benchmark suite
\end{todo}
Le support pour les applications à base de flots de données dans OpenMP est arrivé avec la version 4.0, qui est sortie au démarrage de cette thèse.

Il existait évidemment plusieurs suites de benchmarks : d'une part pour les applications à base de tâches indépendantes et utilisant OpenMP~3.1, et d'autre part pour les applications à base de flots de données, mais écrites dans des languages différents.

L'objectif derrière les KASTORS était double :
\begin{itemize}
    \item Rassembler et proposer une suite d'applications exploitant les dépendances introduites avec OpenMP~4.0
    \item Comparer la version utilisant des flots de données à la version utilisant des synchronisations explicites. Le but étant de montrer que le support exécutif peut gérer les synchronisations plus finement, et par conséquent améliorer les performances sans changer l'algorithme.
\end{itemize}

Les sections suivantes décrivent les différents benchmarks de la suite : d'où ils viennent, ainsi que comment nous les avons étendu pour utiliser les dépendances de données.

\subsection{Description des applications}

Les applications suivantes proviennent de différentes suites de benchmarks, et ont été modifiées afin d'utiliser les dépendances de données plutôt que d'autres moyen de synchronisation.

\subsubsection{Factorisations de Cholesky, QR, et LU (PLASMA)}

\begin{lstlisting}[caption=Format de l'algorithme dynamique,label=lst:kastors:dyn]
wrapper_algorithm_dynamic_call(...) {
  // code sequentiel
  for (...)
    QUARK_Insert_Task(wrapper_blas_function, packed_parameters);
  // code sequentiel
  for (...)
    QUARK_Insert_Task(
        wrapper_another_blas_function,
        packed_parameters);
  // code sequentiel
}
\end{lstlisting}
\begin{lstlisting}[caption=Format de l'algorithme OpenMP,label=lst:kastors:dyn-omp]
algorithm_call(...) {
    // code sequentiel
    for (...)
#pragma omp task depend(inout:array[...])
        blas_function(...);
    // code sequentiel
    for (...)
#pragma omp task depend(inout:array[...])
        another_blas_function(...);
    // code sequentiel
}
\end{lstlisting}

La bibliothèque PLASMA~\cite{Kurzak2013} développée à ICL/UTK met à disposition un grand nombre d'algorithmes d'algèbre linéaire, optimisés pour les architectures multi-coeurs.
Plusieurs implémentations de chaque algoritme sont disponibles, utilisant soit un ordonnancement statique, soit un ordonnancement dynamique.
Les algorithmes à ordonnancement dynamique sont construit sur le support exécutif QUARK~\cite{YarKhan2011}, qui utilise un modèle avec dépendances de données pour ordonnancer les tâches.

Les trois algorithmes que nous avons sélectionné sont les factorisations de Cholesky, QR, et LU, respectivement nommés DPOTRF, DGEQRF, et DGETRF dans PLASMA.
Ils opèrent tous sur des matrices de nombres flottant à double précision (type |double|).

L'implémentation initiale utilise plusieurs niveaux de wrappers, avec packing et unpacking de paramètres à chaque niveau, ce qui affecte la lisibilité du code et augmente grandement le risque d'erreur.

Les listings~\ref{lst:kastors:dyn} et~\ref{lst:kastors:dyn-omp} montrent respectivement la version dynamique originale, et les transformation que l'on a fait pour porter le code en OpenMP~4.0.
Dans la version originale, la function |wrapper_blas_function| effectue l'unpacking des paramètres avant d'appeler la vraie fonction BLAS/LAPACK sur laquelle elle est construite.
La transformation en OpenMP~4.0 a donné lieu au retrait de plusieurs niveau d'encapsulation, ce qui facilite la lecture du code, la maintenabilité du code, et enlève le besoin de gérer ces paramètres.

\subsubsection{Jacobi}

Cet algorithme résout l'équation de Poisson sur le carré unitaire [0,1]x[0,1], qui est divisé en une grille de NxN points espacés régulièrement.

TODO: expliquer à quoi correspond un stencil ?

Cette application repose sur un noyau de calcul qui est en fait un stencil à 5 points en 2 dimensions.
Ce noyau est appliqué successivement jusqu'à ce qu'une convergence soit détectée.
Nous avons implémenté deux versions bloquées de ce noyau, en utilisant d'une part des tâches sans dépendances, et d'autre part des tâches avec dépendances.

\subsubsection{SparseLU}

\begin{lstlisting}[caption=LU utilisant des tâches indépendantes,label=lst:kastors:sparseLU]
for (k=0; k<NB; k++) {
  lu0(M[k*NB+k]);
  for (j=k+1; j<NB; j++)
#pragma omp task untied shared(M)
    fwd(M[k*NB+k], M[k*NB+j]);

  for (i=k+1; i<NB; i++)
#pragma omp task untied shared(M)
    bdiv(M[k*NB+k], M[i*NB+k]);

#pragma omp taskwait

  for (i=k+1; i<NB; i++)
    for (j=k+1; j<NB; j++)
#pragma omp task untied shared(M)
      bmod(M[i*NB+k],
           M[k*NB+j],
           M[i*NB+j]);
#pragma omp taskwait
}
\end{lstlisting}

\begin{lstlisting}[caption=LU utilisant des tâches avec dépendances,label=lst:kastors:sparseLU-deps]
for (k=0; k<NB; k++) {
#pragma omp task untied shared(M)\
    depend(inout: M[k*NB+k:BS*BS])
  lu0(M[k*NB+k]);
  for (j=k+1; j<NB; j++)
#pragma omp task untied shared(M)\
    depend(in: M[k*NB+k:BS*BS])\
    depend(inout: M[k*NB+j:BS*BS])
    fwd(M[k*NB+k], M[k*NB+j]);

  for (i=k+1; i<NB; i++)
#pragma omp task untied shared(M)\
    depend(in: M[k*NB+k:BS*BS])\
    depend(inout: M[i*NB+k:BS*BS])
    bdiv(M[k*NB+k], M[i*NB+k]);

  for (i=k+1; i<NB; i++)
    for (j=k+1; j<NB; j++)
#pragma omp task untied shared(M)\
   depend(in: M[i*NB+k:BS*BS])\
   depend(in: M[k*NB+j:BS*BS])\
   depend(inout: M[i*NB+j:BS*BS])
    bmod(M[i*NB+k],M[k*NB+j],M[i*NB+j]);
}
\end{lstlisting}

\begin{todo}
citer correctement \cite{Duran2009}, Barcelona OpenMP Tasks Suite: A set of benchmarks targeting the exploitation of task parallelism in OpenMP
\end{todo}

Cette application calcule la factorisation LU d'une matrice creuse.
Nous avons modifié l'implémentation originale des BOTS pour ajouter des dépendances de données.
Ces modificiations sont décrites dans les listings~\ref{lst:kastors:sparseLU} and~\ref{lst:kastors:sparseLU-deps}.

\subsubsection{Strassen}

L'application Strassen utilise des décompositions de matrices pour calculer le produit de grandes matrices denses.
De manière similaire à SparseLU, nous avons modifié l'implémentation des BOTS pour ajouter du parallélisme au niveau des additions dans l'algorithme, et nous avons exprimé des dépendances de données plutôt que d'utiliser une synchronisation à base de |taskwait|.


\subsection{Un aperçu des performances}

TODO : ajouter des courbes, des détails sur les compilos/runtimes utilisés, et faire une première visualisation de ce qu'apporte les dépendances.

GRAPHE : 4.2.3 performances générales kastors, tâches vs dépendances (probablement du papier). opportunité pour noter le problème sur jacobi taskdep.

GRAPHE : 5.1.3, courbes motivantes pour l'affinité (ça peut être jacobi, ça peut être l'étude distante/locale des noyaux de Cholesky)

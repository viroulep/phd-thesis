\section{Amélioration de l'expressivité du langage}\label{sec:openmp:langage}

Nous avons proposé plusieurs extensions au langage et à l'API d'OpenMP, dont le but général est de faciliter le travail du support exécutif pour maintenir la proximité entre une tâche et ses données au cours de l'exécution du programme.

\subsection{Description du besoin}

Dans un contexte où l'on souhaite améliorer le contrôle sur les tâches et leurs données, OpenMP~4.0 ne propose que deux fonctionnalités~: les |OMP_PLACES| et |OMP_PROCBIND|, mais cela n'a d'effet que sur le placement des threads sur la topologie, et non sur les tâches qui leur sont attribuées.
Il n'y a rien au sein d'OpenMP qui permet d'exprimer une relation entre une tâche et une donnée ou une partie de la topologie de la machine.

En dehors d'OpenMP, les programmeurs utilisent généralement des bibliothèques ou outils externes dans le but de contrôler le placement des données, tels que MAi~\cite{Pousa2009} et MaMi~\cite{Broquedis2010a}.
L'efficacité de certaines approches peut être remise en cause (comme dans le cas de \emph{numactl}), et les approches utilisant une bibliothèque externe peuvent être relativement intrusives.

Nous avons donc introduit deux types de constructions dans OpenMP~: d'une part un moyen de contrôler la distribution initiale des données manipulées par les tâches, et d'autres part un moyen d'associer les tâches à ces données (ou mieux, à n'importe quelle partie de la machine).

\subsection{Contrôle de la distribution des données}\label{sec:openmp:langage:init}

Utiliser une initialisation séquentielle des données de son application peut avoir des conséquences dramatiques sur les performances, tout spécialement lorsque l'on cible des machines NUMA.
Les données se retrouvent dans ce cas sur un unique nœud, dont le bus mémoire va être complètement saturé lorsque les cœurs de tous les autres nœuds vont avoir besoin des données.

Classiquement les programmeurs effectuent l'allocation et l'initialisation des données de manière séquentielle, et utilisent \emph{numactl} pour en faire la distribution.

Ici on va supposer que, de la même manière que le programmeur exprime le parallélisme de son application à base de tâches, il initialise également les données de son application à l'aide de tâches (qu'il est raisonnable de supposer indépendantes) dans une région parallèle séparée.

Dans la plupart des applications que nous avons utilisées nous avons constaté que l'initialisation des données suivait un schéma où l'allocation et l'initialisation de chacun des blocs est fait au fur et à mesure des besoins ou de la construction des structures de données de l'application.

L'initialisation des données devant être groupées ensemble a donc lieu dans une même tâche.
Les solutions de l'état de l'art consistent à allouer, ou migrer, les données initialisées par ces tâches.
Plutôt que d'utiliser une technique similaire, nous allons nous baser sur le principe portable du \emph{first-touch}, décrit dans la section~\ref{sec:context:os}.

Nous proposons ici de distribuer les tâches d'initialisations selon une stratégie choisie par l'utilisateur.
Gérer le placement des tâches est plus efficace et moins couteux que de migrer des données, et permet en fait d'arriver au même résultat~: en distribuant les tâches d'initialisations, on distribue les tâches effectuant le \emph{first-touch} des données, ce qui a pour effet de distribuer physiquement ces données.
Par rapport à \emph{numactl} cela présente également l'avantage de garder sur le même nœud NUMA les données s'étendant sur plusieurs pages.


Pour pouvoir indiquer au support exécutif quelles tâches marquer comme "tâches d'initialisation" et comment gérer leur placement sur la topologie, nous avons mis en place une clause s'appliquant sur une région parallèle~:

\begin{lstlisting}
init(random | cyclic | cyclicnuma)
\end{lstlisting}

Elle indique à l'ordonnanceur de tâches que pour la région parallèle courante les tâches prêtes devraient être distribuées sur la machine en suivant une stratégie :

\begin{description}
  \item [random :]
    distribution aléatoire sur les cœurs de la machine.
  \item [cyclic :]
    distribution de manière cyclique sur les cœurs de la machine.
  \item [cyclicnuma :]
    distribution cyclique sur les nœuds de la machine.
\end{description}


Malgré une restriction dans la manière de réaliser l'initialisation des données de l'application, cet ajout permet au programmeur de spécifier une distribution de données avec une modification minimale du code, et plus efficacement qu'avec les solutions existantes.

Si cette restriction peut être trop forte pour certaines applications, il est aussi possible pour les cas particuliers de spécifier une clause affinité stricte (définie dans la section suivante) sur chacune des tâches d'initialisation.



\subsection{Ajout d'une clause affinité}\label{sec:openmp:langage:affinity}

Pour permettre d'exprimer une association entre une tâche et une donnée (ou un élément de la topologie), nous avons proposé l'introduction du mot clé |affinity| dans le langage OpenMP, qui a été présentée lors du Workshop International sur OpenMP (IWOMP) en 2016~\cite{Virouleau2016b}.
Comme constaté dans le chapitre~\ref{chap:contrib:characterization} et souvent mentionné dans la littérature, un point clé pour obtenir de bonnes performances sur des architectures NUMA est de garantir la proximité entre une tâche et ses ressources.

L'objectif de cette clause est donc de permettre à l'utilisateur de pouvoir spécifier un lien privilégié - une \emph{affinité} - entre une tâche et un élément de l'architecture.
On distingue donc trois types d'affinité que le programmeur pourrait avoir besoin d'exprimer :

\begin{description}
    \item [affinité à un thread :]
      le support exécutif devrait essayer d'ordonnancer la tâche sur le thread donné.
    \item [affinité à un nœud NUMA :]
      le support exécutif devrait essayer d'ordonnancer la tâche sur n'importe
      quel thread du nœud NUMA donné.

    \item [affinité à une donnée :]
      quand une tâche devient prête pour l'exécution, le support exécutif devrait
      l'ordonnancer sur n'importe quel thread attaché au nœud NUMA sur lequel
      la donnée a été physiquement allouée.
\end{description}

De plus, le programmeur peut indiquer si cette affinité est \emph{stricte}, indiquant que la tâche \textbf{doit} s'exécuter sur la ressource indiquée.
Si le programmeur n'indique pas une affinité stricte, l'ordonnanceur peut décider d'exécuter la tâche sur une ressource différente, pour équilibrer la charge de calcul par exemple.

Cette extension visant les constructions de type tâche, elle a été implémentée comme une nouvelle clause pour la directive |task|. La syntaxe proposée est la suivante~:

\begin{lstlisting}
affinity([node | thread | data]: expr[, strict])
\end{lstlisting}

Dans tous les cas l'expression |expr| est un entier naturel, mais en fonction du type d'affinité l'entier est interprété d'une manière spécifique :

\begin{description}
  \item [thread :]
    |expr| est interprétée comme un id de thread. On définit ici la notion d'id de thread comme l'indice du thread au sein des |OMP_PLACES| pour la \textit{team} OpenMP courante.
    Voici une illustration, en prenant une exécution sur quatre threads avec comme valeur |OMP_PLACES="{2},{5},{8},{9}"| :
    \begin{itemize}
      \item Les quatre \emph{threads} qui constituent la \emph{team} vont être ici placés sur quatre \emph{cœurs} de la machine d'indice |2|, |5|, |8|, et |9|.
      \item Les \emph{threads} étant toujours numérotés à partir de |0| dans une \emph{team}, la correspondance entre thread et cœur sera donc la suivante~: le thread d'indice |0| sera donc placé sur le cœur |2|, le thread d'indice |1| sera placé sur le cœur |5|, et ainsi de suite.
    \end{itemize}
  \item [node :]
    |expr| est interprétée comme un id de nœud NUMA. Comme pour le cas précédent, la notion d'id est définie relativement aux places de la \textit{team} OpenMP courante.
    En reprenant l'exemple précédent, supposons que les cœurs 2,5,8, et 9 sont physiquement situés sur 2 nœuds NUMA différents. Il y aura alors 2 nœuds NUMA déduits des places, et les ids utilisés pourront être 0 ou 1.
  \item [data :]
    |expr| est interprétée comme une adresse mémoire. Si le nœud NUMA associé à la donnée ne peut être déterminé, le nœud utilisé par défaut est le nœud local.
\end{description}

Si |expr| désigne une ressource hors limites, la valeur considérée par le support exécutif est prise modulo le nombre de ressources correspondantes.

\subsection{Extension des fonctions du support exécutif}

Si les points précédents décrivent des extensions directement au niveau des constructions OpenMP, il est également important de pouvoir fournir dynamiquement certaines informations au programmeur au cours de l'exécution du programme.
Dans ce but nous avons également ajouté quelques fonctions à l'API d'OpenMP, dont le but est de fournir des informations à propos de l'architecture et de la \emph{team} OpenMP courante :

\begin{lstlisting}
// Retourne le nombre de nœuds NUMA dans la team
int omp_get_num_nodes(void);

// Retourne le nœud NUMA sur lequel
// la tâches est actuellement exécutée
int omp_get_node_num(void);

// Retourne le nœud NUMA sur lequel la donnée a été allouée
int omp_get_node_from_data(void *ptr);
\end{lstlisting}

Ces fonctions retournant des informations spécifiques à une \emph{team} OpenMP, elles ne peuvent être appelées qu'au sein d'une région parallèle.
Sur les machines sans support NUMA, nous considérons que tous les threads sont sur un unique nœud NUMA.

Nous avons également rendu accessible l'ajout d'affinité sur une tâche à une fonction de l'API :
\begin{lstlisting}
void omp_set_task_affinity(omp_affinitykind_t k,
                           uintptr_t ptr, int strict);
\end{lstlisting}
Cette fonction aura un impact sur la prochaine tâche créée dans la région.
Les paramètres de la fonction correspondent aux paramètres de la clause :

\begin{description}
  \item [omp\_affinitykind\_t k] peut être soit |omp_affinity_thread|, |omp_affinity_node|, ou |omp_affinity_data|.
  \item [uintptr\_t ptr] correspond à une expression désignant la ressource.
  \item [int strict] indique si l'affinité est stricte (|strict != 0|) ou non (|strict == 0|).
\end{description}


\subsection{Notes d'implémentation}

Les extensions ont été implémentées dans le compilateur Clang\footnote{https://gitlab.inria.fr/openmp/clang}, en nous basant sur la version~3.9.

Pour intégrer ces extensions, nous avons dans un premier temps étendu différentes parties du \emph{frontend} de Clang~: la partie en charge de l'analyse syntaxique, pour permettre la compréhension des nouvelles clauses et l'enrichissement de l'arbre syntaxique abstrait avec les informations présentes~;
et la partie en charge de l'analyse sémantique afin d'appliquer certaines restrictions sur les clauses (telles que les constructions sur lesquelles elles peuvent être appliquées, ou le type des données attendu).

Dans un second temps nous avons étendu la génération de code, en ajoutant différents point d'entrée dans l'ABI et en passant les données présentes dans l'arbre.

L'ajout des nouveaux points d'entrées dans l'ABI signifie qu'il faut également rajouter leur prise en compte dans le support exécutif, et que du code (contenant des affinités) compilé par notre version modifiée du compilateur n'est pas compatible avec des supports exécutifs n'implémentant pas ces points d'entrée.


L'extension du support exécutif et l'utilisation des informations fournies par le programmeur sont décrites dans la section suivante.

\section{Exécution précise de noyaux}\label{sec:contribs:outil}

Cette partie se concentre sur la présentation de \outil, un outil que nous avons créé afin de faciliter la réalisation d'expériences avec un contrôle précis sur le placement de noyaux à exécuter ainsi que leurs données.

\subsection{Besoins pour un outil spécifique: \outil}

Il est en général assez facile d'étudier le comportement global d'une application, et d'observer les variations de ce comportement lorsqu'on change certains détails dans l'exécution, comme par exemple via l'utilisation de \emph{numactl}.

En revanche, si l'on connait bien son application, on a envie de pouvoir étudier le comportement précis de certaines de ses parties critiques afin de pouvoir identifier ce qui cause son comportement global.

La suite naturelle de cette identification est de déterminer s'il existe des améliorations possibles pour ce comportement local, et comment l'améliorer en pratique.

Dans le cas d'une application à base de flots de données, chaque partie de l'application est bien identifiée, et correspond à un nœud dans le graphe de tâches.
Toutes les données manipulées par une partie de l'application sont facilement identifiées également, puisqu'il s'agit des connexions entre les nœuds du graphe de tâches.

Dans le contexte d'une machine NUMA, le temps d'exécution d'une tâche dépend à la fois du placement de son exécution, ainsi que du placement de ces données. On a donc envie de pouvoir modéliser le comportement individuel de chaque type de tâche en fonction de son placement et du placement des données qu'elle accède.
Une fois cela fait, cela permettra d'identifier des potentielles variations de comportement, et ajuster les heuristiques d'ordonnancement pour prendre en compte ces variations.

C'est à ce besoin que répond \outil : une fois que l'utilisateur a isolé les parties critiques de son application, \outil lui permet de définir lesquelles il souhaite exécuter et où, et lui garantir cette exécution, avec un certain nombre de variables observables.

Dans la suite de ce chapitre, on appellera l'ensemble des paramètres décrivant cette expérience un \emph{scenario}.

\subsection{Description d'un scenario}

Ce que l'on appelle ici un \emph{scenario} n'est ni plus ni moins que la description d'une expérience.
Par exemple on pourrait vouloir "observer les performances en gigaflops d'une multiplication de matrices carrées sur le cœur 0 d'une machine".
C'est un scenario simple, et l'exemple que l'on prendra pour illustrer les points un peu plus formel qui vont suivre.

En pratique un scenario est défini par les éléments suivants :
\begin{itemize}
 \item Un ensemble de données et variables~;
 \item Une liste d'actions à effectuer~;
 \item Un ensemble de caractéristiques à observer.
\end{itemize}

Cette définition très générique permet beaucoup de flexibilité, et les sections suivantes précisent les différentes caractéristiques de ces points, ainsi que des exemples concrêts d'utilisation.

Il est important que le format de description d'un scenario soit humainement lisible, et ne conduise pas à une recompilation systématique du programme. C'est donc une description en YAML~\cite{YAML} qui a été choisie.

\subsubsection{Données et variables}

Elles sont indispensables car c'est là-dessus que vont se baser les actions du scenario.

L'utilisateur doit fournir les noms et types des variables utilisées en paramètre des différents noyaux, elles peuvent être réutilisées par différents noyaux, mais dans tous les cas l'utilisateur est le seul responsable de leur gestion.

En pratique ces variables peuvent soit être des constantes, ou bien être initialisées par une action dans le scénario.

Pour revenir à l'exemple du scenario simple ou l'on souhaite exécuter une multiplication de matrices carrées - |dgemm| - sur un cœur donné, nous avons besoin de trois matrices |a|, |b|, et |c|, ainsi que d'une taille pour les bloc de données manipulés (qui correspond donc à la largeur de la matrice), |block_size|.

Voici concrêtement à quoi ressemblerait la déclaration de ces données :

\begin{lstlisting}[language=yaml,caption=Exemple de déclaration de variables,label=lst:tool:data-example]
data:
  - a:
    - type: "double *"
  - b:
    - type: "double *"
  - c:
    - type: "double *"
  - block_size:
    - type: "int"
    - value: 256
\end{lstlisting}

\subsubsection{Actions}

C'est là où l'on décrit effectivement les noyaux exécutés au cours du scénario.
L'utilisateur indique une série d'actions à exécuter, et avec quels paramètres.

Chaque action peut avoir les caractéristiques suivantes :
\begin{itemize}
  \item core: nombre entier indiquant le cœur sur lequel exécuter l'action.
  \item kernel: chaine de caractères avec le nom de l'action, correspondant à un noyau connu du programme.
  \item params: liste de variables à passer à l'action, leur nom doit correspondre à des données déclarées dans la section précédente.
  \item repeat: nombre entier indiquant le nombre de fois que cette action doit être répétée.
  \item sync: booléen indiquant s'il faut synchroniser le démarrage de cette action avec celui des autres actions présentes dans les files d'attente des autres cœurs.
\end{itemize}

Si on continue à décrire l'exemple simple d'une multiplication de matrices carrées, il faut que l'on définisse les actions suivantes : l'initialisation de chaque matrice, le lancement du dgemm une fois que ces matrices sont initialisées.
Afin d'avoir une mesure plus précise du comportement du noyau, on peut indiquer une répétition du noyau, ici on choisit 50 pour l'exemple.

Voici en pratique à quoi ressemblerait un tel scenario :
\begin{lstlisting}[language=yaml,caption=Exemple de déclaration d'actions,label=lst:tool:actions-example]
actions:
  - kernel: init_blas_bloc
    sync: false
    params: 
    - a
    - block_size
    core: 0
    # Pour l'initialisation, un seul appel suffit
    repeat: 1
  - kernel: init_blas_bloc
    sync: false
    params: 
    - b
    - block_size
    core: 0
    repeat: 1
  - kernel: init_blas_bloc
    sync: false
    params: 
    - c
    - block_size
    core: 0
    repeat: 1
  - kernel: dgemm
    # Les actions sont executees dans l'ordre de declaration, pour un seul dgemm c'est inutile de synchroniser
    sync: false
    params: 
    - a
    - b
    - c
    - block_size
    core: 0
    # Ici c'est le noyau de calcul, on veut donc le repeter
    repeat: 50
\end{lstlisting}

Ici les trois initialisations et le calcul ont lieu sur le même cœur, et sont déroulés dans l'ordre de création, il n'y a donc pas lieu d'utiliser une synchronisation.
En revanche dans le cas où l'on souhaiterait par exemple observer l'exécution de deux |dgemm| qui s'exécuteraient en même, il faudrait synchroniser leur démarrage.

En supposant que |a|, |b|, |a1|, |b1| ont déjà été initialisés, voilà à quoi ressembleraient les dernières initialisations de |c| et |c1| (dont il n'est pas nécessaire de synchroniser le démarrage), suivi de la création (synchronisée) de deux |dgemm|~:
\begin{lstlisting}[language=yaml,caption=Exemple de déclaration d'actions synchronisées,label=lst:tool:actions-example-sync]
actions:
  # On suppose les autres paramètres
  # des dgemms déjà initialisés
  - kernel: init_blas_bloc
    sync: false
    params: 
    - c
    - block_size
    core: 0
    repeat: 1
  - kernel: init_blas_bloc
    sync: false
    params: 
    - c1
    - block_size
    core: 1
    repeat: 1
  - kernel: dgemm
    sync: true
    params: 
    - a
    - b
    - c
    - block_size
    core: 0
    repeat: 50
  - kernel: dgemm
    sync: true
    params: 
    - a1
    - b1
    - c1
    - block_size
    core: 1
    repeat: 50
\end{lstlisting}


Simplement exécuter ces actions ne nous donnera pas grand chose, il faut donc définir un ensemble de caractéristiques à observer.

\subsubsection{Observateurs}

L'outil propose un certain nombre de caractéristiques observables :

\begin{itemize}
  \item le temps passé dans l'action (en millisecondes).
  \item la performance de l'action en Gflops.
    % Note : valable que pour les noyaux d'algère linéaire parce qu'il faut le nombre de flops de l'action.
  \item des compteurs de performances à travers PAPI
\end{itemize}

En continuant sur notre exemple, voici à quoi ressemblerait la section du scénario si nous souhaitions observer la performance de la multiplication de matrice en Gflops, le nombre de cycles passés dans l'action, ainsi que le nombre de \emph{cache miss} de niveau 3 générés par l'action.

\begin{lstlisting}[language=yaml,caption=Exemple de déclaration d'observateurs,label=lst:tool:watchers-example]
watchers:
  flops_dgemm:
    # Le nombre de flops dépend de la taille de bloc,
    # il faut donc la donner en paramètre
    - block_size
  papi:
    - PAPI_TOT_CYC
    - PAPI_L3_TCM
\end{lstlisting}

L'ensemble des compteurs à observer étant passé tel quel à PAPI, il est donc de la responsabilité de l'utilisateur de fournir un ensemble de compteurs compatibles entre eux.

\subsection{Design de l'outil}

Afin de minimiser le "bruit" lors des expériences, il fallait que l'architecture de l'outil soit simple, avec peu de logique relative au contrôle de l'exécution des tâches et à la synchronisation.

Le flot d'exécution est le suivant :

\paragraph{Lecture et analyse statique du scénario}
L'outil charge le scénario fourni par l'utilisateur, crée les différentes données, et analyse les actions pour déterminer l'ensemble des cœurs physiques qui seront utilisés au cours des actions.

\paragraph{Déroulement des actions}
Pour chacun des cœurs utilisés, un thread est créé et attaché à ce cœur. De plus, une file d'actions (FIFO) est créée pour ce thread.
L'ensemble des actions sont poussées dans les files correspondantes dans l'ordre du fichier.

Les threads exécutent chacun les actions présentes dans leur file, et vont déclencher les mesures de chaque paramètre observé avant et après chaque action.

Lorsque la dernière action du scénario est terminée, l'ensemble des paramètres observés est affiché à l'utilisateur sur la sortie standard.

\subsection{Application et exemples de scénarios}

\outil nous a servi dans deux types de contexte~: pour la caractérisation des machines sur lesquelles nous avons effectuées nos expériences, et pour l'étude détaillées des parties critiques des applications que nous avons utilisées.

La section~\ref{sec:contribs:machines} dresse un profil détaillé des machines et présente une utilisation de \outil pour mesurer certaines caractéristiques de la machine, qui n'aurait pas été facilement mesurable à travers d'autres outils.
La section~\ref{sec:contribs:apps:cholesky} présente une étude de cas de l'une des applications que nous avons utilisé~: la factorisation de Cholesky.
Elle revient sur le fonctionnement de l'outil, les observations préliminaires que nous avons effectué, et la valeur ajoutée qu'a eu \outil dans la compréhension détaillée et l'amélioration des performances de l'application.




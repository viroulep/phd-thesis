
\begin{savequote}[6cm]
<< Some other great quote  >>
\qauthor{Someone}
\end{savequote}
\chapter{Related work}
\chaptertoc

Lorem Ipsum blablabla
%Ce premier chapitre présente brièvement le contexte de cette thèse en section~\ref{sec:intro:contexte}. Puis, nous détaillons les problématiques de recherche en section~\ref{sec:intro:problematique}. Nous présentons les principales contribution de ce travail en section~\ref{sec:intro:demarche}. Ensuite, nous présentons notre cadre applicatif en section~\ref{sec:introduction:digitalhome} et enfin, nous détaillons le plan de ce manuscrit en section~\ref{sec:intro:plan}.

\begin{itemize}
  \item OpenMP
  \item NUMA
  \item Workstealing
\end{itemize}

\section{Runtimes}

OpenMP-related

\subsection{LIBKOMP/Kaapi}
\subsection{OMPSs}
\subsection{StarPU/Kstar}

Others

\subsection{Quark}
\subsection{OpenStream}

\section{NUMA-specific scheduling techniques}


\section{Benchmarking}

\subsection{BOTS}
\subsection{EPCC}
\subsection{NAS}
\subsection{Plasma}
\subsection{Rodinia}
\subsection{SPEC}
\subsection{KASTORS}

  - rel sched/openmp

\cite{Zhuravlev2012}, Survey of Scheduling Techniques for Addressing Shared Resources in Multicore Processors

\cite{Sbirlea2015}, Polyhedral Optimizations for a Data-Flow Graph Language

  - rel sched/numa

\cite{Selva2015}, (thèse) Performance Monitoring of Throughput Constrained Dataflow Programs Executed On Shared-Memory Multi-core Architectures

\cite{Reinman2015}, NUMA-aware scheduling for both memory- and compute-bound tasks

\cite{Drebes2014}, Topology-Aware and Dependence-Aware Scheduling and Memory Allocation for Task-Parallel Languages

\cite{Durand2013}, An Efficient OpenMP Loop Scheduler for Irregular Applications on Large-Scale NUMA Machines

\cite{Clet2014}, Evaluation of OpenMP Task Scheduling Algorithms for Large NUMA Architectures

\cite{Tahan2014}, Towards Efficient OpenMP Strategies for Non-Uniform Architectures

\cite{Pilla2014}, Topology-Aware Load Balancing for Performance Portability over Parallel High Performance Systems

\cite{Broquedis2010a}, ForestGOMP: an efficient OpenMP environment for NUMA architectures

  - rel bench

\cite{Rodinia2010}, A characterization of the Rodinia benchmark suite with comparison to contemporary CMP workloads

  - rel bench openmp

(vieux?)\cite{Nanjegowda2009}, Scalability evaluation of barrier algorithms for OpenMP

\cite{Duran2009}, Barcelona OpenMP Tasks Suite: A set of benchmarks targeting the exploitation of task parallelism in OpenMP

\cite{Kurzak2013}, Multithreading in the PLASMA Library

\cite{Jin2004}, Performance Characteristics of the Multi-Zone NAS Parallel Benchmarks.

\cite{Bailey1994}, The NAS Parallel Benchmarks

\cite{Muller2012}, SPEC OMP2012 -- an Application Benchmark Suite for Parallel Systems Using OpenMP

  - rel task/numa

\cite{Wienke2012}, Task-Parallel Programming on NUMA Architectures

\cite{Olivier2012}, OpenMP task scheduling strategies for multicore NUMA systems

\cite{Terboven2012}, Task-Parallel Programming on NUMA Architectures

\cite{Wittmann2011}, Optimizing ccNUMA locality for task-parallel execution under OpenMP and TBB on multicore-based systems


  - rel affinity/heterogeneous

\cite{Bleuse2014}, Scheduling Data Flow Program in XKaapi: A New Affinity Based Algorithm for Heterogeneous Architectures
\cite{Lima2015}, Design and analysis of scheduling strategies for multi-CPU and multi-GPU architectures

  - rel numa/linear algegra

\cite{Al-Omairy2015}, Dense Matrix Computations on NUMA Architectures with Distance-Aware Work Stealing

  - rel task

\cite{Olivier2013}, Characterizing and mitigating work time inflation in task parallel programs

\cite{Gautier2007}, Kaapi: A Thread Scheduling Runtime System for Data Flow Computations on Cluster of Multi-Processors

\cite{StarPU}, StarPU: A Unified Platform for Task Scheduling on Heterogeneous Multicore Architectures

\cite{OMPSs}, Ompss: a proposal for programming heterogeneous multi-core architectures

\cite{Broquedis2012}, LIBKOMP, an Efficient openMP Runtime System for Both Fork-join and Data Flow Paradigms

  - rel numa/openmp

\cite{Huang2010}, Enabling locality-aware computations in OpenMP

\cite{Yu2017}, Design and Implementation of Bandwidth-aware Memory Placement and Migration Policies for Heterogeneous Memory Systems

\cite{Weng2002}, Implementing OpenMP Using Dataflow Execution Model for Data Locality and Efficient Parallel Execution

(vieux?)\cite{Nikolopoulos2001}, Exploiting Memory Affinity in OpenMP Through Schedule Reuse

\cite{HPF}, HPF (owner compute rule)

  - rel energy/openmp

\cite{Shafik2015}, Adaptive Energy Minimization of OpenMP Parallel Applications on Many-Core Systems

\cite{Porterfield2013}, Power measurement and concurrency throttling for energy reduction in OpenMP programs

\cite{Porterfield2013a}, OpenMP and MPI application energy measurement variation

\cite{Nandamuri2015}, Power and energy footprint of OpenMP programs using OpenMP runtime API

\cite{Alessi2015}, Application-level energy awareness for OpenMP

  - rel energy

\cite{Hackenberg2015}, An Energy Efficiency Feature Survey of the Intel Haswell Processor

\cite{Davidovic2015}, Energy efficiency of parallel multicore programs

\cite{Bao2016}, Static and Dynamic Frequency Scaling on Multicore CPUs

 - rel TODO ?!
\cite{Saad2013} Iterative Methods for Sparse Linear Systems
\cite{Karypis1998}, A Fast and High Quality Multilevel Scheme for Partitioning Irregular Graphs

\section{Characterization}

\input{tex/rw/openmp}
\input{tex/rw/numa}

\section{Techniques d'ordonnancement ciblant les machines NUMA}\label{sec:rw:numa}

\subsection{Introduction}

L'ensemble des travaux existant traitant des architectures NUMA est suffisamment grand pour qu'il existe plusieurs papiers résumant ces travaux et synthétisant les avancées.

%NUMA-aware scheduling for both memory- and compute-bound tasks
\paragraph{Reinman~\cite{Reinman2015}} a regroupé différents travaux selon le type de tâches qu'ils ciblaient, et propose en conclusion des recommandations lorsque l'on cherche à ordonnancer des programmes à base de tâches sur des machines NUMA.

L'auteur distingue principalement deux types de tâches : compute-bound et memory-bound.
Si certaines des 8 recommandations sont très spécifiques aux types de tâches, d'autres décrivent bien les points qu'il faut avoir en tête lorsque l'on cible les architectures NUMA.
Il indique notamment l'importance de la distribution des données de l'application sur l'ensemble des noeuds NUMA, l'importance de la localité des données, ainsi que l'importance de garder les tâches et leur données ensemble lors du vol de travail.



Décrire l'ensemble des travaux qui ont été effectués dans ce domaine n'est pas possible, voir dans certains cas n'est pas pertinent, puisque les architectures et langages évoluent.
Les sections qui suivent se concentrent sur les travaux qui nous paraissent être toujours d'actualité, et qui ont eu un impact sur le développement de nos travaux.



\subsection{Grouper les threads de calculs proches de leurs données}

L'importance de prendre en compte la hiérarchie dans les architectures NUMA est très bien reflétée par la quantité d'articles en rapport avec ce sujet.
De plus la problématique de la localité des données rencontrée sur les architectures NUMA est présente également dans d'autres contexte.
Les manières dont elle est traitée dans les travaux qui suivent ont servies d'inspiration pour les extensions et techniques proposées dans les chapitres~\ref{chap:contrib:characterization} et~\ref{chap:contrib:openmp}.

Les techniques utilisées par les travaux suivant ont tous en commun le groupement des threads sur des éléments topologiquement proches dans la hiérarchie.
L'objectif derrière cette idée est de rester proches des données.


%Evaluation of OpenMP Task Scheduling Algorithms for Large NUMA Architectures
\paragraph{Clet-Ortega et al.~\cite{Clet2014}} ont étudié et évalué plusieurs façons de décorer la topologie de l'architecture, en privilégiant des listes de tâches privées par thread, parcourues de manière hiérarchique.




%OpenMP task scheduling strategies for multicore NUMA systems
\paragraph{Olivier et al.~\cite{Olivier2012}} ont évalué des stratégies hiérarchiques d'ordonnancement de tâches, en utilisant des structures centralisées ou distribuées.
Ils introduisent un ensemble de threads par noeud NUMA, appelé \emph{shepherd}, permettant à l'ordonnanceur hiérarchique d'avoir de meilleures performances qu'avec les autres approches.


%Towards Efficient OpenMP Strategies for Non-Uniform Architectures
\paragraph{Tahan et al.~\cite{Tahan2014}} ont étudié le comportement des programmes à base de tâches OpenMP sur les systèmes NUMA, dans le support exécutif Nanos d'OMPSS (voir section~\ref{subsec:rw:ompss}).
Ils ont ajouté deux ordonnanceurs de tâches, DFWSPT et DFWSRPT, prennant en compte la priorité des tâches, et essayant de également de diminuer la distance à la mémoire lors de l'équilibrage de charge.

%Task-Parallel Programming on NUMA Architectures
%Optimizing ccNUMA locality for task-parallel execution under OpenMP and TBB on multicore-based systems
Des travaux similaires ont été réalisés par Terboven et al.~\cite{Terboven2012}, ainsi que par Wittman et Hager~\cite{Wittmann2011}.

Ces travaux se sont concentrés sur les tâches indépendantes.
L'ajout des dépendances avec OpenMP~4.0 amène un nouvel ensemble d'informations concernant l'utilisation des données par les tâches, qui n'a pas été traités par les travaux mentionnés.

\cite{Al-Omairy2015}, Dense Matrix Computations on NUMA Architectures with Distance-Aware Work Stealing
Queue par noeud numa, vol seulement dans cette queue, tri par priorité.
Proche de nos travaux sur cholesky


\paragraph{HPF~\cite{HPF} (High Performance Fortran)} est une extension de Fortran 90.
Le principe est de distribuer la \emph{propriété} de chaque élément des tableaux manipulés, et de répartir la charge de travail (les instructions ou groupe d'instructions) sur les processeurs en fonction des éléments manipulés.


%An Efficient OpenMP Loop Scheduler for Irregular Applications on Large-Scale NUMA Machines
\paragraph{Durand et al.~\cite{Durand2013}} ont développé un ordonnanceur de boucles irrégulières, permettant de générer du travail à la voler, et de garder les tâches "à proximité".


\cite{Pilla2014}, Topology-Aware Load Balancing for Performance Portability over Parallel High Performance Systems


\cite{Bleuse2014}, Scheduling Data Flow Program in XKaapi: A New Affinity Based Algorithm for Heterogeneous Architectures

\cite{Lima2015}, Design and analysis of scheduling strategies for multi-CPU and multi-GPU architectures

\subsection{Déplacer les données en fonction des calculs (ou les deux ?)}

%ForestGOMP: an efficient OpenMP environment for NUMA architectures
\paragraph{ForestGOMP~\cite{Broquedis2010a}} est un support exécutif ciblant spécifiquement les architectures NUMA.
Ses fonctionnalités incluent un ordonnanceur de threads hiérarchiques, groupés selon les équipes de threads OpenMP afin de maximiser la localité des données.

\cite{Yu2017}, Design and Implementation of Bandwidth-aware Memory Placement and Migration Policies for Heterogeneous Memory Systems


\cite{Drebes2014}, Topology-Aware and Dependence-Aware Scheduling and Memory Allocation for Task-Parallel Languages





(vieux?)\cite{Weng2002}, Implementing OpenMP Using Dataflow Execution Model for Data Locality and Efficient Parallel Execution

(vieux?)\cite{Nikolopoulos2001}, Exploiting Memory Affinity in OpenMP Through Schedule Reuse



\subsection{Energie et OpenMP (TODO, ou pas)}


\cite{Hackenberg2015}, An Energy Efficiency Feature Survey of the Intel Haswell Processor

\cite{Davidovic2015}, Energy efficiency of parallel multicore programs

\cite{Bao2016}, Static and Dynamic Frequency Scaling on Multicore CPUs

\cite{Shafik2015}, Adaptive Energy Minimization of OpenMP Parallel Applications on Many-Core Systems

\cite{Porterfield2013}, Power measurement and concurrency throttling for energy reduction in OpenMP programs

\cite{Porterfield2013a}, OpenMP and MPI application energy measurement variation

\cite{Nandamuri2015}, Power and energy footprint of OpenMP programs using OpenMP runtime API

\cite{Alessi2015}, Application-level energy awareness for OpenMP


\subsection{TODO : inclassés}

\cite{Selva2015}, (thèse) Performance Monitoring of Throughput Constrained Dataflow Programs Executed On Shared-Memory Multi-core Architectures

\cite{Zhuravlev2012}, Survey of Scheduling Techniques for Addressing Shared Resources in Multicore Processors
Travaux point de vue OS, pour un processeur multicoeurs (UMA !).
Contention-aware scheduler.
Cool, mais seulement à l'intérieur d'un noeud.

\cite{Olivier2013}, Characterizing and mitigating work time inflation in task parallel programs


\cite{Sbirlea2015}, Polyhedral Optimizations for a Data-Flow Graph Language
Orienté transformation de boucles, pas vraiment en rapport direct avec la thèse


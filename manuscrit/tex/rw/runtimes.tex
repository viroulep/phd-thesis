\section{Compilateurs populaires et leurs supports exécutif}\label{sec:rw:compilers}


Avant de rentrer dans le vif du sujet, il nous paraît important d'insister sur la distinction entre compilateur et support exécutif.

Tous les modèles de programmation ne sont pas implémenté par tous les compilateurs, mais par contre le fonctionnement général reste le même.
Le code source va contenir des directives (|#pragma|) ou des appels de fonctions décrits par le modèle de programmation. Le code source va ensuite être plus ou moins transformé par le compilateur.

La section~\ref{sec:context:others:costs} décrit en détail la transformation de code s'opérant dans le cas d'OpenMP.
La conséquence directe de cette transformation est qu'il existe un \textbf{couplage fort} entre le compilateur et le support exécutif.

Dans le cas spécifique d'OpenMP il y a principalement 3 compilateurs qui implémentent complètement (et suivent rapidement) le standard : GCC, ICC, et Clang.


\subsubsection{GCC}

Le compilateur GCC est livré avec son support exécutif par défaut : libGOMP.
Les développeurs du compilateur sont généralement très réactifs aux évolutions du standard, et GCC supporte OpenMP~4.0 depuis la version 4.9.

libGOMP ne dispose pas de stratégie d'ordonnancement particulièrement dédiée aux architectures NUMA.
L'ordonnancement des tâches est gérée par la technique du vol de travail, avec une queue de tâche unique pour l'ensemble des threads.



\subsubsection{ICC}


ICC est livré avec son support exécutif - open source~\footnote{https://www.openmprtl.org/} - libIOMP.
Il supporte la version~4.0 d'OpenMP depuis la version 15.0.

ICC dispose d'un support privilégié pour accélérateur (construction |target|) ciblant les Xeon Phi.


\subsubsection{Clang/LLVM}

Le support d'OpenMP dans Clang a été ajouté d'un coup, contrairement à GCC où il a été progressivement enrichi.
Intel a tout d'abord ajouté le support dans un clone de Clang : \emph{clang-omp}~\footnote{https://clang-omp.github.io/}.
Il y a ensuite eu un effort d'ingénierie pour l'inclure dans Clang, et la license du support exécutif d'Intel a été changé pour être compatible avec l'infrastructure LLVM, ce qui a permis de l'embarquer directement dans le code source, en le renommant libOMP.

OpenMP~4.0 est supporté depuis la version 3.8 de Clang (sauf pour la partie |target|).

\subsubsection{Compatibilité}

Dans un scenario idéal, on pourrait à loisir interchanger les compilateurs et supports exécutifs utilisés : par exemple compiler du code avec GCC, et l'exécuter en utilisant le support exécutif d'Intel.

Clang et ICC compilant pour le même support exécutif, eux deux sont effectivement interchangeables.

En revanche libGOMP et libIOMP/libOMP utilisent des ABIs différentes, les codes générés par GCC et Clang/ICC sont donc a priori incompatibles.
Heureusement les développeurs de libOMP ont implémentés une couche d'interconnexion entre les deux ABIs, ce qui permet effectivement d'interchanger à loisir ces 3 compilateurs populaires et leurs support exécutifs.

\section{Autres supports exécutifs}\label{sec:rw:other-runtimes}

Il existe un certain nombres d'autres supports exécutifs, pour OpenMP comme d'autres modèle de programmation.
Les sections ci après introduisent ceux ayant des thématiques très proches de cette thèse.

\subsection{xKaapi}

Kaapi~\cite{Gautier2007} est un support exécutif à base de tâche avec dépendances.
Il dispose d'une couche - libKOMP~\cite{Broquedis2012} - implémentant à la fois les ABIs de libGOMP et libOMP, ce qui permet de l'utiliser directement en compilant via GCC ou Clang, et en changeant le support exécutif chargé à l'exécution.

Son moteur d'ordonnancement fonctionne par vol de travail.
Le support exécutif dispose d'une vision hiérarchique de la machine, ce qui a pu offrir une base propice pour l'ajout d'heuristiques d'ordonnancement plus complexes que celles initialement présentes (décrites en section~\ref{sec:contrib:ws:heuristics}).

L'outil de génération de traces disponible permet également une analyse pointue du comportement des applications, à travers les compteurs de performances matériels et une analyse par type de tâche.


\subsection{OmpSs}\label{subsec:rw:ompss}

OmpSs~\cite{OMPSs} est un modèle de programmation visant à étendre OpenMP, visant à étendre le support du parallélisme asynchrone (à base de tâches avec dépendances par exemple), et de l'hétérogénéité.
La syntaxe est les détails dans l'utilisation peuvent être légèrement différents, mais les constructions et concepts restent les même.

OmpSs est composé d'un compilateur, \emph{Mercurium}, et d'un support exécutif \emph{Nanos++}.

\subsection{StarPU}

StarPU~\cite{StarPU} est une librairie de programmation parallèle à base de tâche avec dépendances.
Son support exécutif hétérogène permet de cibler aussi bien des processeurs standards que des accélérateurs, à partir du moment où le programmeur a fourni différentes versions des tâches pour les différentes architectures cibles.

StarPU utilise des techniques avancées d'ordonnancement sur ressources hétérogènes, et propose différentes techniques d'ordonnancement en fonction du but recherché.
Point de vue performances, les ordonnancements de tâches disponibles peuvent être soit purement \emph{online} (tel que le vol de travail - \emph{ws}), ou dériver de techniques initialement \emph{offline} comme leurs ordonnanceurs \emph{dm}, où un ordonnancement initial similaire à HEFT est effectué.

\subsection{Quark}

\cite{Kurzak2013}, Multithreading in the PLASMA Library
TODO : se documenter

\subsection{OpenStream}

OpenStream~\cite{Pop2013}.
Cite Andi

Modèle de programmation par flôt de données.
Fonctionnalités NUMA.


Blabla

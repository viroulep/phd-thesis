\section{Supports exécutifs}\label{sec:rw:other-runtimes}

Il existe un certain nombre d'autres supports exécutifs, pour OpenMP comme pour d'autres modèles de programmation.
Les sections ci-après introduisent ceux ayant des thématiques très proches de cette thèse.

\subsection{XKaapi}

Kaapi~\cite{Gautier2007} est un support exécutif, à base de tâches avec dépendances, ciblant originellement les clusters de processeurs multicœurs.
Il a ensuite été étendu pour cibler spécifiquement les architectures hétérogènes, et à au passage été renommé XKaapi~\cite{Gautier2013}.
Il repose sur hwloc pour découvrir la topologie de la machine, et utilise ces informations à de multiples endroits.

Le moteur d'ordonnancement de XKaapi fonctionne par vol de travail~\cite{Lima2015}, et implémente les étapes critiques de \emph{sélection} et de \emph{placement} décrites dans la section~\ref{sec:context:runtimes:ws}. Il est facile d'ajouter des heuristiques additionnelles pour ces deux étapes, ce qui nous a permis d'implémenter dans ce support exécutif les extensions décrites dans la section~\ref{sec:contrib:ws:heuristics}.

Le nombre de files de tâches repose sur les informations fournies par hwloc~: XKaapi implémente une file de tâches par niveau de la hiérarchie (i.e.~: une file par cœur, une file par nœud NUMA, etc.), qui sont éventuellement utilisées par les heuristiques.

Pour la gestion de ces files, XKaapi implémente le protocole THE~\cite{cilk5} proposé par Cilk. Ce protocole permet de faire, dans la plupart des cas, des accès concurrents à la même file de tâches de manière non bloquante. Le principe est le suivant~: le \emph{voleur} - distant - va venir prendre des tâches en tête de file, et la \emph{victime} (ou le thread local) va venir ajouter ou retirer des tâches en queue de file.
Le seul conflit se produit lorsque la file n'a qu'un seul élément, se traduisant par la prise d'un verrou.

En plus de l'utilisation de ce protocole, XKaapi peut effectuer de l'agrégation de requêtes de vols~: lorsque plusieurs voleurs vont effectuer des requêtes sur la même victime, seul le premier voleur arrivé va effectuer la requête de vol, et récupérer suffisamment de tâches pour l'ensemble des voleurs~\cite{Besseron2009}.
Les gains théoriques liés à ce mécanisme ont été étudiés par Tchiboukdjian et al.~\cite{Tchiboukdjian2010a}.

Pour observer le comportement des applications exécutées, XKaapi dispose d'un outil de génération de traces.
Cela permet une analyse pointue du comportement de l'application, via les compteurs de performance matériels et une analyse par type de tâche.
Cet outil nous a permis de faire des observations préliminaires déjà très poussées, sur une étude de cas abordée dans la section~\ref{sec:contribs:apps:cholesky:observations}.

XKaapi est principalement utilisé comme prototype de recherche, et a été utilisé pour l'implémentation de certains travaux proches des thématiques de cette thèse, en particulier celle de la localité des données~\cite{Durand2013, Bleuse2014, Lima2015}.

Du point de vue de la compatibilité avec OpenMP, elle a été progressive et plusieurs solutions existent ou ont existé~: KaCC~\cite{Lementec2011} était un compilateur source à source basé sur ROSE~\cite{Quinlan2003} qui implémentait les dépendances par dessus les tâches indépendantes d'OpenMP~3.0, et permettait donc à XKaapi d'exécuter les programmes OpenMP à base de tâches.
%Pour supporter des codes scientifiques tel qu'Europlexus, XKaapi a ensuite supporté les boucles OpenMP~\cite{Gautier2013b}.
Lorsqu'Intel a commencé à travailler sur l'implémentation d'OpenMP~4.0 dans Clang, un nouveau compilateur source à source basé sur Clang a vu le jour~: KStar.
Ce compilateur, supporté par l'ADT Inria du même nom, avait pour but de cibler XKaapi et StarPU à partir des pragmas OpenMP.
Une fois que le support d'OpenMP dans Clang a été stable, le support d'XKaapi dans KStar a été abandonné.

La manière actuelle de cibler XKaapi est d'utiliser une couche de compatibilité pour OpenMP au niveau binaire, nommée libKOMP~\cite{Broquedis2012}.
Cette couche implémente à la fois les ABIs de libGOMP et libOMP, ce qui permet de l'utiliser pour exécuter des programmes OpenMP~4.0 directement en compilant via GCC ou Clang, et en changeant le support exécutif chargé à l'exécution.



\subsection{libGOMP}

libGOMP~\cite{Novillo2006} est le support exécutif OpenMP fourni avec le compilateur GCC.

Au niveau des fonctionnalités, il implémente la totalité du standard OpenMP~4.5.
Comme la majorité des supports exécutifs, libGOMP réutilise les threads qui sont créés entre différentes régions parallèles successives, pour éviter d'avoir à payer le coût de destruction/création d'un thread inutilement.
Les gestions des constructions à base de boucles et de tâches sont complètement séparées dans le support exécutif.
Vis-à-vis de la hiérarchie de l'architecture cible, il n'y a aucune disposition particulière pour essayer de la prendre en compte.

Pour la gestion des tâches, libGOMP ne dispose que d'une seule file de tâches par \emph{team}~\cite{libGOMP7.3}, donc une seule file pour l'ensemble des threads, et l'ordonnancement est effectué à travers un algorithme glouton.
Si fonctionnellemment cette caractéristique n'est pas un problème, cela peut avoir un impact sur les performances compte tenu du fait que tous les threads devront sérialiser leurs accès à la même struture de données.
Cela se voit d'ailleurs sur la figure~\ref{fig:context:granularity} illustrant l'impact de la granularité des tâches~: pour des petites tailles de bloc (et donc un grand nombre de tâches), libGOMP est loin derrière à cause du surcoût entrainé par la gestion de la liste de tâches.
Pour amoindrir ce problème, libGOMP limite le nombre de tâches total dans la file de tâches~: si un thread essaie de pousser une tâche et que cette limite est atteinte, alors la tâche sera invoquée séquentiellement par le thread.
En pratique le nombre limite de tâches est égal à 64 multiplié par le nombre de threads utilisés.

Néanmoins, en tant que support exécutif grand public et largement utilisé, il constitue une référence intéressante.

\subsection{libOMP}

libOMP est le support exécutif OpenMP fourni avec le compilateur Clang, directement basé sur le support exécutif d'Intel fourni avec ICC.
Ils partagent donc exactement les mêmes caractéristiques.

Compte tenu du fait qu'il a été développé à la base par des développeurs d'Intel, une partie de ses fonctionnalités ont été motivées par l'exploitation du matériel produit par Intel comme le Xeon Phi.

De manière similaire à libGOMP, la gestion des boucles et des tâches est séparée, et les threads (et même les \emph{teams} et leurs structures de données associées) sont réutilisés par les régions parallèles successives.

En revanche libOMP se distingue de libGOMP de par ses structures de données~: chaque thread d'une \emph{team} possède une file de tâches propre.
Il fonctionne par vol de travail, et les heuristiques de base pour les fonctions d'ordonnancement sont les suivantes~:
la sélection d'une file à voler a lieu aléatoirement parmi les files de tâches disponibles~;
lors de vols successifs, le voleur essaye en priorité la dernière file dans laquelle il a réussi à voler une tâche.
Le placement des tâches prêtes a lieu dans la file du thread courant.

Comme dans libGOMP, si le nombre de tâches dépasse un certain seuil (dans ce cas précis, si la file de tâches est pleine), alors la tâche c'est pas réellement enfilée mais elle est directement exécutée via un appel séquentiel.

Bien que ce mécanisme n'ait pas été initialement conçu pour permettre d'interchanger des stratégies, cela proposait une base suffisamment solide pour accueillir les extensions que nous proposons dans le chapitre~\ref{chap:contrib:openmp}.
Les modifications que nous avons apportées à ce support exécutif sont détaillées dans la section~\ref{sec:contribs:perf_eval:libkomp}.




\subsection{OmpSs}\label{subsec:rw:ompss}

OmpSs~\cite{OMPSs} est un modèle de programmation visant à étendre OpenMP, en particulier le support du parallélisme asynchrone (à base de tâches avec dépendances par exemple), et de l'hétérogénéité.
La syntaxe et les détails dans l'utilisation peuvent être légèrement différents, mais les constructions et concepts restent les mêmes.
OmpSs est composé d'un compilateur, \emph{Mercurium}, et d'un support exécutif \emph{Nanos++}.

Du point de vue de la gestion des tâches, Nanos peut fonctionner soit par un algorithme de liste, soit par vol de travail.
Par défaut l'ordonnanceur fonctionne à l'aide d'une unique file de tâches à priorité, néanmoins certains ordonnanceurs fonctionnent avec une file de tâches par cœur.
Il ne dispose pas d'ordonnanceur prenant en compte la localité des données, mais certains d'entre eux disposent de files de tâches associées à certains éléments de la hiérarchie (cœur ou nœud NUMA), afin de favoriser le vol de tâche <<proche>>.


\subsection{OpenStream}

OpenStream~\cite{Pop2013} est un modèle de programmation par flots de données dérivant directement d'OpenMP~3.0.
Le programmeur définit des flots de données ainsi que des tâches opérant en lecture et/ou écriture sur une certaine quantité de données d'un flot (appelée \emph{window}).
Concrètement les flots de données peuvent être vus comme des tableaux, et les tâches opèrent sur un certain nombre d'éléments contigus de celui-ci.
Le support exécutif étudie ensuite l'ordre d'écriture dans les différentes parties d'un flot pour construire un graphe de dépendance des tâches, qui sera ensuite ordonnancé sur la machine.

Ce modèle se rapproche donc très fortement des tâches avec dépendances qui sont apparues dans la version suivante d'OpenMP.
OpenStream utilise un support exécutif avec des extensions pour les architectures NUMA, nous l'avons présenté plus en détails dans la section~\ref{sec:rw:numa:thread-data}.

\subsection{StarPU}

StarPU~\cite{StarPU} est une librairie de programmation parallèle à base de tâches avec dépendances.
Le programmeur décrit les tâches et leurs différentes implémentations (CPU, GPU, ...), ce qui permet à son support exécutif hétérogène permet de cibler aussi bien des processeurs standards que des accélérateurs.
La seule restriction est qu'il n'est pas possible d'utiliser des tâches récursives.

StarPU utilise des techniques avancées d'ordonnancement sur ressources hétérogènes, et propose différentes techniques d'ordonnancement en fonction du but recherché.
D'un point de vue performances, les ordonnancements de tâches disponibles peuvent être soit purement \emph{online} (tel que le vol de travail - \emph{ws}), ou dériver de techniques initialement \emph{offline} comme leurs ordonnanceurs \emph{dm}, où un ordonnancement initial similaire à HEFT est effectué.

\subsection{QUARK}

QUARK~\cite{Kurzak2013} (QUeing And Runtime for Kernels) fut le support exécutif privilégié pour la bibliothèque d'algèbre linéaire PLASMA, qui utilise maintenant OpenMP, et dont certaines de nos applications sont adaptées.

Il fonctionne lui aussi à base de tâches, qui sont exclusivement des fonctions de l'utilisateur.
La création de tâches se fait à l'aide d'appels au support exécutif, et en plus d'un pointeur sur la fonction tâche le programmeur indique les variables manipulées et le type d'accès effectué.

Cela permet donc à QUARK de déterminer un ordre d'exécution sur les tâches pour son ordonnancement.
L'avantage principal de QUARK par rapport aux autres modèles de programmation similaires est qu'il propose des extensions spécifiques à certains algorithmes d'algèbre linéaire présents dans PLASMA.


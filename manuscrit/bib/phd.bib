@article{Lima2015,
  author    = {Jo{\~{a}}o V. F. Lima and
               Thierry Gautier and
               Vincent Danjean and
               Bruno Raffin and
               Nicolas Maillard},
  title     = {Design and analysis of scheduling strategies for multi-CPU and multi-GPU
               architectures},
  journal   = {Parallel Computing},
  volume    = {44}, pages     = {37--52},
  year      = {2015}
}


@book{Saad2003,
 author = {Saad, Y.},
 title = {Iterative Methods for Sparse Linear Systems},
 year = {2003},
 isbn = {0898715342},
 edition = {2nd},
 publisher = {Society for Industrial and Applied Mathematics},
 address = {Philadelphia, PA, USA},
}

@article{Karypis1998,
 author = {Karypis, George and Kumar, Vipin},
 title = {A Fast and High Quality Multilevel Scheme for Partitioning Irregular Graphs},
 journal = {SIAM J. Sci. Comput.},
 issue_date = {Aug. 1998},
 volume = {20},
 number = {1},
 month = dec,
 year = {1998},
 issn = {1064-8275},
 pages = {359--392},
 numpages = {34},
 publisher = {Society for Industrial and Applied Mathematics},
 address = {Philadelphia, PA, USA},
 keywords = {fill-reducing orderings, finite element computations, graph partitioning, parallel computations},
}

@inproceedings{HPF,
 author = {Kennedy, Ken and Koelbel, Charles and Zima, Hans},
 title = {The Rise and Fall of High Performance Fortran: An Historical Object Lesson},
 booktitle = {Proceedings of the Third ACM SIGPLAN Conference on History of Programming Languages},
 series = {HOPL III},
 year = {2007},
 isbn = {978-1-59593-766-7},
 location = {San Diego, California},
 pages = {7-1--7-22},
 url = {http://doi.acm.org/10.1145/1238844.1238851},
 doi = {10.1145/1238844.1238851},
 acmid = {1238851},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {High Performance Fortran (HPF), compilers, parallel computing},
}

@inproceedings{Duran2009,
  title={Barcelona OpenMP Tasks Suite: A set of benchmarks targeting the exploitation of task parallelism in OpenMP},
  author={Duran, A. and Teruel, X. and Ferrer, R. and Martorell, X. and Ayguade, E.},
  booktitle={Parallel Processing, 2009. ICPP'09. International Conference on},
  pages={124--131},
  year={2009},
  organization={IEEE}
}

@inproceedings{Durand2013,
author="Durand, Marie
and Broquedis, Fran{\c{c}}ois
and Gautier, Thierry
and Raffin, Bruno",
chapter="An Efficient OpenMP Loop Scheduler for Irregular Applications on Large-Scale NUMA Machines",
booktitle = {Proceedings of the 9th International Conference on OpenMP in the Era of Low Power Devices and Accelerators},
location = {Canberra, Australia},
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="141--155",
}


@Inbook{Bleuse2014,
author="Bleuse, Rapha{\"e}l
and Gautier, Thierry
and Lima, Jo{\~a}o V. F.
and Mouni{\'e}, Gr{\'e}gory
and Trystram, Denis",
chapter="Scheduling Data Flow Program in XKaapi: A New Affinity Based Algorithm for Heterogeneous Architectures",
title="Euro-Par 2014 Parallel Processing: 20th International Conference, Porto, Portugal, August 25-29, 2014. Proceedings",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="560--571",
}


@inproceedings{Gautier2007,
  title = {{Kaapi:} A Thread Scheduling Runtime System for Data Flow Computations on Cluster of Multi-Processors},
  author = {Gautier, T. and Besseron, X. and Pigeon, L.},
  booktitle = {PASCO'07},
  year = 2007,
}

@article{Kurzak2010,
 author = {Kurzak, Jakub and Ltaief, Hatem and Dongarra, Jack and Badia, Rosa M.},
 title = {Scheduling Dense Linear Algebra Operations on Multicore Processors},
 journal = {Concurr. Comput. : Pract. Exper.},
 issue_date = {January 2010},
 volume = {22},
 number = {1},
 month = jan,
 year = {2010},
 issn = {1532-0626},
 pages = {15--44},
 numpages = {30},
 url = {http://dx.doi.org/10.1002/cpe.v22:1},
 doi = {10.1002/cpe.v22:1},
 acmid = {1673014},
 publisher = {John Wiley and Sons Ltd.},
 address = {Chichester, UK},
 keywords = {Cholesky, LU, QR, direct acyclic graph, dynamic scheduling, factorization, linear algebra, matrix factorization, multicore, scheduling, task graph},
} 

@techreport{YarKhan2011,
author      = {YarKhan, A. and Kurzak, J. and Dongarra, J.},
title       = {QUARK Users' Guide: QUeueing And Runtime for Kernels},
booktitle   = {University of Tennessee Innovative Computing Laboratory Technical Report},
institution = {Innovative Computing Laboratory, University of Tennessee},
year        = {2011}
}

@inbook{Kurzak2013,
        Author = {Jakub Kurzak and Piotr Luszczek and Asim YarKhan and Mathieu Faverge and Julien Langou and Henricus Bouwmeester and Jack Dongarra},
        Booktitle = {Multicore Computing},
        Doi = {doi:10.1201/b16293-6},
        Isbn = {978-1-4398-5434-1},
        Pages = {119-141},
        Publisher = {Chapman and Hall/CRC},
        Title = {Multithreading in the PLASMA Library},
        Title1 = {Chapman \& Hall/CRC Computer \& Information Science Series},
        Url = {http://dx.doi.org/10.1201/b16293-6},
        Year = {2013}
}

@misc{openmp40,
    author = {{OpenMP Architecture Review Board}},
    title = {{OpenMP} Application Program Interface Version 4.0},
    month = jul,
    year = 2013,
    url = {\url{http://www.openmp.org/mp-documents/OpenMP4.0.0.pdf}}
}
@misc{openmp45,
    author = {{OpenMP Architecture Review Board}},
    title = {{OpenMP} Application Program Interface Version 4.5},
    month = nov,
    year = 2015,
    url = {\url{http://www.openmp.org/wp-content/uploads/openmp-4.5.pdf}}
}
@misc{ARM-Cortex-R,
  Author = {ARM},
  title = {ARM Cortex-R series processors manual},
  year = 2010,
  url = {\utl{http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.set.cortexr/index.html}}
}



@inproceedings{Jin2004,
  author = {Jin, Haoqiang and der Wijngaart, Rob F. Van},
  biburl = {http://www.bibsonomy.org/bibtex/231f9027d87bde21d9b566b1b5cad42d8/dblp},
  booktitle = {IPDPS},
  date = {2004-07-01},
  description = {dblp},
  ee = {http://csdl.computer.org/comp/proceedings/ipdps/2004/2132/01/213210006babs.htm},
  interhash = {d43f28164c6bc39bad1e4c1509255c27},
  intrahash = {31f9027d87bde21d9b566b1b5cad42d8},
  isbn = {0-7695-2132-0},
  keywords = {dblp},
  publisher = {IEEE Computer Society},
  timestamp = {2004-07-01T00:00:00.000+0200},
  title = {Performance Characteristics of the Multi-Zone NAS Parallel Benchmarks.},
  url = {http://dblp.uni-trier.de/db/conf/ipps/ipdps2004-c.html#JinW04},
  year = 2004
}

@techreport{Bailey1994,
  author = {Bailey, D. and Barszcz, E. and Barton, J. and Browning, D. and Carter, R. and Dagum, L. and Fatoohi, R. and Fineberg, S. and Frederickson, P. and Lasinski, T. and Schreiber, R. and Simon, H. and Venkatakrishnan, V. and Weeratunga, S.},
  biburl = {http://www.bibsonomy.org/bibtex/2ff8666b816fc452419d5cbe5926ecb48/snowball},
  institution = {Department of Mathematics and Computer Science, Emory University},
  interhash = {112db9cdefe790e487610010504b5f32},
  intrahash = {ff8666b816fc452419d5cbe5926ecb48},
  keywords = {imported},
  month = {March},
  number = {RNR-94-007},
  optaddress = {Atlanta, GA 30322},
  timestamp = {2006-03-09T08:15:35.000+0100},
  title = {{The NAS Parallel Benchmarks}},
  type = {Report},
  year = 1994
}

@inproceedings{Muller2012,
 author = {M\"{u}ller, Matthias S. and Baron, John and Brantley, William C. and Feng, Huiyu and Hackenberg, Daniel and Henschel, Robert and Jost, Gabriele and Molka, Daniel and Parrott, Chris and Robichaux, Joe and Shelepugin, Pavel and van Waveren, Matthijs and Whitney, Brian and Kumaran, Kalyan},
 title = {SPEC OMP2012 -- an Application Benchmark Suite for Parallel Systems Using OpenMP},
 booktitle = {Proceedings of the 8th International Conference on OpenMP in a Heterogeneous World},
 series = {IWOMP'12},
 year = {2012},
 isbn = {978-3-642-30960-1},
 location = {Rome, Italy},
 pages = {223--236},
 numpages = {14},
 url = {http://dx.doi.org/10.1007/978-3-642-30961-8_17},
 doi = {10.1007/978-3-642-30961-8_17},
 acmid = {2345830},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
 keywords = {SPEC, benchmark, energy efficiency, openMP},
}

@INPROCEEDINGS{Rodinia2010,
author={Shuai Che and Sheaffer, J.W. and Boyer, M. and Szafaryn, L.G. and Liang Wang and Skadron, K.},
booktitle={Workload Characterization (IISWC), 2010 IEEE International Symposium on},
title={A characterization of the Rodinia benchmark suite with comparison to contemporary CMP workloads},
year={2010},
month={Dec},
pages={1-11},
keywords={computer graphics;coprocessors;principal component analysis;GPU;NVIDIA GeForce GTX480;Parsec;Rodinia benchmark suite;contemporary CMP workloads;graphics processors unit;principal component analysis;space coverage;Benchmark testing;Computational fluid dynamics;Computer architecture;Graphics processing unit;Heart;Instruction sets;Kernel},
doi={10.1109/IISWC.2010.5650274},}

@Article{StarPU,
author = {C{\'e}dric Augonnet and Samuel Thibault and Raymond Namyst and Pierre-Andr{\'e} Wacrenier},
title = {{StarPU: A Unified Platform for Task Scheduling on Heterogeneous Multicore Architectures}},
journal = {Concurrency and Computation: Practice and Experience, Special Issue: Euro-Par 2009},
volume = 23,
issue = 2,
pages = {187--198},
year = 2011,
month = FEB,
publisher = {John Wiley & Sons, Ltd.},
doi = {10.1002/cpe.1631},
url = {http://hal.inria.fr/inria-00550877},
keywords = {StarPU}
}

@article{OMPSs,
  title={Ompss: a proposal for programming heterogeneous multi-core architectures},
  author={Duran, Alejandro and Ayguad{\'e}, Eduard and Badia, Rosa M and Labarta, Jes{\'u}s and Martinell, Luis and Martorell, Xavier and Planas, Judit},
  journal={Parallel Processing Letters},
  volume={21},
  number={02},
  pages={173--193},
  year={2011},
  publisher={World Scientific}
}

@inproceedings{Clet2014,
  author    = {J{\'{e}}r{\^{o}}me Clet{-}Ortega and
               Patrick Carribault and
               Marc P{\'{e}}rache},
  title     = {Evaluation of OpenMP Task Scheduling Algorithms for Large {NUMA} Architectures},
  booktitle = {Euro-Par 2014 Parallel Processing - 20th International Conference,
               Porto, Portugal, August 25-29, 2014. Proceedings},
  pages     = {596--607},
  year      = {2014},
  url       = {http://dx.doi.org/10.1007/978-3-319-09873-9_50},
  doi       = {10.1007/978-3-319-09873-9_50},
  timestamp = {Tue, 12 Aug 2014 12:39:51 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/europar/Clet-OrtegaCP14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}


@article{Tahan2014,
  author    = {Oussama Tahan},
  title     = {Towards Efficient OpenMP Strategies for Non-Uniform Architectures},
  journal   = {CoRR},
  volume    = {abs/1411.7131},
  year      = {2014},
  url       = {http://arxiv.org/abs/1411.7131},
  timestamp = {Mon, 01 Dec 2014 14:32:13 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/Tahan14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{Terboven2012,
  author    = {Christian Terboven and
               Dirk Schmidl and
               Tim Cramer and
               Dieter an Mey},
  title     = {Task-Parallel Programming on {NUMA} Architectures},
  booktitle = {Euro-Par 2012 Parallel Processing - 18th International Conference,
               Euro-Par 2012, Rhodes Island, Greece, August 27-31, 2012. Proceedings},
  pages     = {638--649},
  year      = {2012},
  url       = {http://dx.doi.org/10.1007/978-3-642-32820-6_63},
  doi       = {10.1007/978-3-642-32820-6_63},
  timestamp = {Fri, 24 Aug 2012 17:03:22 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/europar/TerbovenSCM12},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{Olivier2012,
  author    = {Stephen Olivier and
               Allan Porterfield and
               Kyle B. Wheeler and
               Michael Spiegel and
               Jan F. Prins},
  title     = {OpenMP task scheduling strategies for multicore {NUMA} systems},
  journal   = {{IJHPCA}},
  volume    = {26},
  number    = {2},
  pages     = {110--124},
  year      = {2012},
  url       = {http://dx.doi.org/10.1177/1094342011434065},
  doi       = {10.1177/1094342011434065},
  timestamp = {Mon, 11 Jun 2012 20:34:21 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/ijhpca/OlivierPWSP12},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}


@article{Wittmann2011,
  author    = {Markus Wittmann and
               Georg Hager},
  title     = {Optimizing ccNUMA locality for task-parallel execution under OpenMP
               and {TBB} on multicore-based systems},
  journal   = {CoRR},
  volume    = {abs/1101.0093},
  year      = {2011},
  url       = {http://arxiv.org/abs/1101.0093},
  timestamp = {Mon, 05 Dec 2011 18:05:15 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/abs-1101-0093},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{Broquedis2010,
  author    = {Fran{\c{c}}ois Broquedis and
               J{\'{e}}r{\^{o}}me Clet{-}Ortega and
               Stephanie Moreaud and
               Nathalie Furmento and
               Brice Goglin and
               Guillaume Mercier and
               Samuel Thibault and
               Raymond Namyst},
  title     = {hwloc: {A} Generic Framework for Managing Hardware Affinities in {HPC}
               Applications},
  booktitle = {Proceedings of the 18th Euromicro Conference on Parallel, Distributed
               and Network-based Processing, {PDP} 2010, Pisa, Italy, February 17-19,
               2010},
  pages     = {180--186},
  year      = {2010},
  url       = {http://dx.doi.org/10.1109/PDP.2010.67},
  doi       = {10.1109/PDP.2010.67},
  timestamp = {Tue, 03 Feb 2015 17:12:49 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/pdp/BroquedisCMFGMTN10},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@phdthesis{Pilla2014,
  TITLE = {{Topology-Aware Load Balancing for Performance Portability over Parallel High Performance Systems}},
  AUTHOR = {Pilla, La{\'e}rcio L.},
  URL = {https://tel.archives-ouvertes.fr/tel-00981136},
  SCHOOL = {{Universit{\'e} de Grenoble ; UFRGS}},
  YEAR = {2014},
  MONTH = Apr,
  KEYWORDS = {Computer architecture ; Parallel programming ; Scheduling ; Programmation Parall{\`e}le ; Profiling ; Ordonnancement ; Architecture des ordinateurs},
  TYPE = {Theses},
  PDF = {https://tel.archives-ouvertes.fr/tel-00981136/file/ThA_se_LaA_rcio_LIMA_PILLA_2014-1.pdf},
  HAL_ID = {tel-00981136},
  HAL_VERSION = {v1},
}

@article{cilk5,
 author = {Frigo, Matteo and Leiserson, Charles E. and Randall, Keith H.},
 title = {The Implementation of the Cilk-5 Multithreaded Language},
 journal = {SIGPLAN Not.},
 issue_date = {May 1998},
 volume = {33},
 number = {5},
 month = may,
 year = {1998},
 pages = {212--223},
 numpages = {12},
  publisher = {ACM},
} 


@inproceedings{Broquedis2012,
 author = {Broquedis, Fran\c{c}ois and Gautier, Thierry and Danjean, Vincent},
 title = {LIBKOMP, an Efficient openMP Runtime System for Both Fork-join and Data Flow Paradigms},
 booktitle = {Proceedings of the 8th International Conference on OpenMP in a Heterogeneous World},
 series = {IWOMP'12},
 year = {2012},
 isbn = {978-3-642-30960-1},
 location = {Rome, Italy},
 pages = {102--115},
 numpages = {14},
 url = {http://dx.doi.org/10.1007/978-3-642-30961-8_8},
 doi = {10.1007/978-3-642-30961-8_8},
 acmid = {2345818},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
 keywords = {data-flow programming, openMP, runtime systems, task parallelism},
} 

@inproceedings{Tchiboukdjian2010,
  author    = {Marc Tchiboukdjian and
               Vincent Danjean and
               Thierry Gautier and
               Fabien Le Mentec and
               Bruno Raffin},
  title     = {A Work Stealing Scheduler for Parallel Loops on Shared Cache Multicores},
  booktitle = {Euro-Par 2010 Parallel Processing Workshops - HeteroPar, HPCC, HiBB,
               CoreGrid, UCHPC, HPCF, PROPER, CCPI, VHPC, Ischia, Italy, August 31-September
               3, 2010, Revised Selected Papers},
  pages     = {99--107},
  year      = {2010},
  url       = {http://dx.doi.org/10.1007/978-3-642-21878-1_13},
  doi       = {10.1007/978-3-642-21878-1_13},
  timestamp = {Tue, 17 Apr 2012 09:27:52 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/europar/TchiboukdjianDGMR10},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@Article{Broquedis2010a,
author = {Fran\c{c}ois Broquedis and Nathalie Furmento and Brice Goglin and Pierre-Andr{\'e} Wacrenier and Raymond Namyst},
title = {{ForestGOMP: an efficient OpenMP environment for NUMA architectures}},
journal = {International Journal on Parallel Programming, Special Issue on OpenMP; Guest Editors: Matthias S. M\"uller and Eduard Ayguade},
year = 2010,
volume = 38,
number = 5,
pages = {418-439},
publisher = {Springer},
doi = {10.1007/s10766-010-0136-3},
url = {http://hal.inria.fr/inria-00496295},
keywords = {Marcel, ForestGOMP, MaMI, NUMA, hwloc} 
}

@inbook{Virouleau2016b,
address = {Cham},
annote = {NULL},
author = {Virouleau, Philippe and Roussel, Adrien and Broquedis, Fran{\c{c}}ois and Gautier, Thierry and Rastello, Fabrice and Gratien, Jean-Marc},
booktitle = {OpenMP: Memory, Devices, and Tasks: 12th International Workshop on OpenMP, IWOMP 2016, Nara, Japan, October 5-7, 2016, Proceedings},
doi = {10.1007/978-3-319-45550-1_5},
editor = {Maruyama, Naoya and de Supinski, Bronis R and Wahib, Mohamed},
file = {:home/fifi/inria/these/these-viroulea/papers/affinity/iwomp2016.pdf:pdf},
isbn = {978-3-319-45550-1},
pages = {61--73},
publisher = {Springer International Publishing},
title = {{Description, Implementation and Evaluation of an Affinity Clause for Task Directives}},
url = {http://dx.doi.org/10.1007/978-3-319-45550-1{\_}5},
year = {2016}
}
@book{Virouleau2014,
abstract = {{\textcopyright} Springer International Publishing Switzerland 2014. The recent introduction of task dependencies in the OpenMP specification provides new ways of synchronizing tasks. Application programmers can now describe the data a task will read as input and write as output, letting the runtime system resolve fine-grain dependencies between tasks to decide which task should execute next. Such an approach should scale better than the excessive global synchronization found in most OpenMP 3.0 applications. As promising as it looks however, any new feature needs proper evaluation to encourage application programmers to embrace it. This paper introduces the KASTORS benchmark suite designed to evaluate OpenMP tasks dependencies.We modified state-of-theart OpenMP 3.0 benchmarks and data-flow parallel linear algebra kernels to make use of tasks dependencies. Learning from this experience, we propose extensions to the current OpenMP specification to improve the expressiveness of dependencies. We eventually evaluate both the GCC/libGOMP and the CLANG/libIOMP implementations of OpenMP 4.0 on our KASTORS suite, demonstrating the interest of task dependencies compared to taskwait-based approaches.},
author = {Virouleau, Philippe and Brunet, Pierrick and Broquedis, François and Furmento, Nathalie and Thibault, Samuel and Aumage, Olivier and Gautier, Thierry},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
issn = {16113349},
keywords = {Benchmarks,KASTORS,OpenMP,Runtime systems,Task dependencies},
title = {{Evaluation of OpenMP dependent tasks with the KASTORS benchmark suite}},
volume = {8766},
year = {2014}
}
@book{Virouleau2016a,
abstract = {{\textcopyright} Springer International Publishing Switzerland 2016. The recent addition of data dependencies to the OpenMP 4.0 standard provides the application programmer with a more flexible way of synchronizing tasks. Using such an approach allows both the compiler and the runtime system to know exactly which data are read or written by a given task, and how these data will be used through the program lifetime. Data placement and task scheduling strategies have a significant impact on performances when considering NUMA architectures. While numerous papers focus on these topics, none of them has made extensive use of the information available through dependencies. One can use this information to modify the behavior of the application at several levels: during initialization to control data placement and during the application execution to dynamically control both the task placement and the tasks stealing strategy, depending on the topology. This paper introduces several heuristics for these strategies and their implementations in our OpenMP runtime Xkaapi.We also evaluate their performances on linear algebra applications executed on a 192-core NUMA machine, reporting noticeable performance improvement when considering both the architecture topology and the tasks data dependencies. We finally compare them to strategies presented previously by related works.},
author = {Virouleau, Philippe and Broquedis, François and Gautier, Thierry and Rastello, Fabrice},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-43659-3_39},
isbn = {9783319436586},
issn = {16113349},
keywords = {Benchmark,NUMA,OpenMP,Runtime systems,Scheduling,Task dependencies,Work-stealing,Xkaapi},
title = {{Using data dependencies to improve task-based scheduling strategies on numa architectures}},
volume = {9833},
year = {2016}
}

// TODO
@article{Paper2017,
author = {Paper, Conference},
file = {:home/fifi/inria/these/biblio/autotuning-static-diavastos.pdf:pdf},
number = {September},
title = {{Auto-tuning Static Schedules for Task Data-flow Applications}},
year = {2017}
}
// TODO
@article{Diavastos2017,
author = {Diavastos, Andreas and Trancoso, Pedro},
file = {:home/fifi/inria/these/biblio/a31-diavastos-switches-runtime.pdf:pdf},
number = {3},
title = {{SWITCHES: A Lightweight Runtime for Dataflow Execution of Tasks on Many-Cores}},
volume = {14},
year = {2017}
}

@inproceedings{Yu2017,
 author = {Yu, Seongdae and Park, Seongbeom and Baek, Woongki},
 title = {Design and Implementation of Bandwidth-aware Memory Placement and Migration Policies for Heterogeneous Memory Systems},
 booktitle = {Proceedings of the International Conference on Supercomputing},
 series = {ICS '17},
 year = {2017},
 isbn = {978-1-4503-5020-4},
 location = {Chicago, Illinois},
 pages = {18:1--18:10},
 articleno = {18},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/3079079.3079092},
 doi = {10.1145/3079079.3079092},
 acmid = {3079092},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {bandwidth-aware memory placement and migration policies, heterogeneous memory systems},
} 

@inproceedings{Stanisic2016,
  TITLE = {{Fast and Accurate Simulation of Multithreaded Sparse Linear Algebra Solvers}},
  AUTHOR = {Stanisic, Luka and Agullo, Emmanuel and Buttari, Alfredo and Guermouche, Abdou and Legrand, Arnaud and Lopez, Florent and Videau, Brice},
  URL = {https://hal.inria.fr/hal-01180272},
  BOOKTITLE = {{The 21st IEEE International Conference on Parallel and Distributed Systems}},
  ADDRESS = {Melbourne, Australia},
  YEAR = {2015},
  MONTH = Dec,
  KEYWORDS = {Sparse Linear Algebra ; Mumps ; Starpu-simgrid ; HPC ; Simgrid ; Runtime},
  PDF = {https://hal.inria.fr/hal-01180272/file/QRMSTARSG_article.pdf},
  HAL_ID = {hal-01180272},
  HAL_VERSION = {v2},
}

@article{Huang2010,
abstract = {Locality of computation is key to obtaining high performance on a broad variety of parallel architectures and applications. It is moreover an essential component of strategies for energy-efficient computing. OpenMP is a widely available industry standard for shared memory programming. With the pervasive deployment of multi-core computers and the steady growth in core count, a productive programming model such as OpenMP is increasingly expected to play an important role in adapting applications to this new hardware. However, OpenMP does not provide the programmer with explicit means to program for locality. Rather it presents the user with a “flat” memory model. In this paper, we discuss the need for explicit programmer control of locality within the context of OpenMP and present some ideas on how this might be accomplished. We describe potential extensions to OpenMP that would enable the user to manage a program's data layout and to align tasks and data in order to minimize the cost of data accesses. We give examples showing the intended use of the proposed features, describe our current implementation and present some experimental results. Our hope is that this work will lead to efforts that would help OpenMP to be a major player on emerging, multi- and many-core architectures.},
author = {Huang, Lei and Jin, Haoqiang and Yi, Liqi and Chapman, Barbara},
doi = {10.3233/SPR-2010-0307},
file = {:home/fifi/inria/these/biblio/185421.pdf:pdf},
issn = {10589244},
journal = {Scientific Programming},
keywords = {Locality of computation,OpenMP,memory programming,programming models},
number = {3-4},
pages = {169--181},
title = {{Enabling locality-aware computations in OpenMP}},
volume = {18},
year = {2010}
}
@article {Marowka2004,
author = {Marowka, Ami and Liu, Zhenying and Chapman, Barbara},
title = {OpenMP-oriented applications for distributed shared memory architectures},
journal = {Concurrency and Computation: Practice and Experience},
volume = {16},
number = {4},
publisher = {John Wiley & Sons, Ltd.},
issn = {1532-0634},
url = {http://dx.doi.org/10.1002/cpe.752},
doi = {10.1002/cpe.752},
pages = {371--384},
keywords = {OpenMP, data locality, NAS Parallel Benchmarks, programming model},
year = {2004},
}

@article{Shafik2015,
annote = {NULL},
author = {Shafik, Rishad A. and Das, Anup and Yang, Sheng and Merrett, Geoff and Al-Hashimi, Bashir M.},
doi = {10.1145/2701310.2701311},
file = {:home/fifi/dev/energy/related{\_}work/p19-Shafik.pdf:pdf},
isbn = {9781450333436},
journal = {Proceedings of the 6th Workshop on Parallel Programming and Run-Time Management Techniques for Many-core Architectures - PARMA-DITAM '15},
keywords = {Energy minimization,Many-core,OpenMP},
pages = {19--24},
title = {{Adaptive Energy Minimization of OpenMP Parallel Applications on Many-Core Systems}},
url = {http://dl.acm.org/citation.cfm?id=2701310.2701311},
year = {2015}
}
@article{Porterfield2013,
abstract = {Understanding on-node application power and performance characteristics is critical to the push toward exascale computing. In this paper, we present an analysis of factors that impact both performance and energy usage of OpenMP applications. Using hardware performance counters in the Intel Sandy bridge X86-64 architecture, we measure energy usage and power draw for a variety of OpenMP programs: simple micro-benchmarks, a task parallel benchmark suite, and a hydrodynamics mini-App of a few thousand lines. The evaluation reveals substantial variations in energy usage depending on the algorithm, the compiler, the optimization level, the number of threads, and even the temperature of the chip. Variations of 20{\%} were common and in the extreme were over 2X. In most cases, performance increases and energy usage decreases as more threads are used. However, for programs with sub-linear speedup, minimal energy usage often occurs at a lower thread count than peak performance. Our findings informed the design and implementation of an adaptive run time system that automatically throttles concurrency using data measured on-line from hardware performance counters. Without source code changes or user intervention, the thread scheduler accurately decides when energy can be conserved by limiting the number of active threads. For the target programs, dynamic runtime throttling consistently reduces power and overall energy usage by up to 3{\%}. {\textcopyright} 2013 IEEE.},
annote = {NULL},
author = {Porterfield, Allan K. and Olivier, Stephen L. and Bhalachandra, Sridutt and Prins, Jan F.},
doi = {10.1109/IPDPSW.2013.15},
file = {:home/fifi/inria/these/biblio/06650969.pdf:pdf},
isbn = {978-0-7695-4979-8},
journal = {Proceedings - IEEE 27th International Parallel and Distributed Processing Symposium Workshops and PhD Forum, IPDPSW 2013},
keywords = {High Performance Computing,OpenMP,Power-Aware Computing},
pages = {884--891},
title = {{Power measurement and concurrency throttling for energy reduction in OpenMP programs}},
year = {2013}
}
@article{Porterfield2013a,
abstract = {Power, energy, and compute time are all important metrics that can act as either objectives or constraints in program or system optimization. Recent microprocessors include sensors (counters) for monitoring these metrics as well as on-chip system controllers that may use this information. Code optimization is relatively straightforward if the measurements are stable and repeatable over time on nominally identical hardware, if there is a lot of variance it becomes very difficult. This paper describes experiments that expose the variability of performance and energy usage on recent Intel processors for some parallel benchmarks using shared memory (OpenMP) and message passing (MPI) programming models. During the start up phase going from a quiescent to a "hot" steady state temperature differences of greater than 26°C were seen resulting in run-to-run energy differences as large as 10{\%}. Even in steady state, run-to-run variability in execution time and energy usage were problematic. The patterns of variability found in execution time and energy consumption pose a challenge to simple strategies for running performance experiments as part of a tuning framework.},
annote = {NULL},
author = {Porterfield, Allan and Fowler, Rob and Bhalachandra, Sridutt and Wang, Wei},
doi = {10.1145/2536430.2536437},
file = {:home/fifi/dev/energy/related{\_}work/a7-porterfield.pdf:pdf},
isbn = {9781450325042},
journal = {Proceedings of the 1st International Workshop on Energy Efficient Supercomputing - E2SC '13},
pages = {1--8},
title = {{OpenMP and MPI application energy measurement variation}},
url = {http://dl.acm.org/citation.cfm?id=2536430.2536437},
year = {2013}
}
@article{Nandamuri2015,
annote = {NULL},
author = {Nandamuri, Anilkumar and Malik, Abid M. and Qawasmeh, Ahmad and Chapman, Barbara M.},
doi = {10.1109/E2SC.2014.11},
file = {:home/fifi/dev/energy/related{\_}work/anil{\_}E2SC{\_}2014-2hpbzzt.pdf:pdf},
isbn = {9781479970360},
journal = {Proceedings of E2SC 2014: 2nd International Workshop on Energy Efficient Supercomputing - Held in Conjunction with SC 2014: The International Conference for High Performance Computing, Networking, Storage and Analysis},
keywords = {Energy,OpenMP,Performance Analysis,Power,Runtime API},
pages = {79--88},
title = {{Power and energy footprint of OpenMP programs using OpenMP runtime API}},
year = {2015}
}
@article{Alessi2015,
abstract = {This book constitutes the refereed proceedings of the 11th International Workshop on OpenMP, held in Aachen, Germany, in October 2015. The 19 technical full papers presented were carefully reviewed and selected from 22 submissions. The papers are organized in topical sections on applications, accelerator applications, tools, extensions, compiler and runtime, and energy.},
annote = {NULL},
author = {Alessi, Ferdinando and Thoman, Peter and Georgakoudis, Giorgis and Fahringer, Thomas and Nikolopoulos, Dimitrios S.},
doi = {10.1007/978-3-319-24595-9_16},
file = {:home/fifi/inria/these/biblio/2015{\_}iwomp{\_}app{\_}energy{\_}omp.pdf:pdf},
isbn = {9783319245942},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {219--232},
title = {{Application-level energy awareness for OpenMP}},
volume = {9342},
year = {2015}
}

@article{Libutti2014,
abstract = {Mainstream multicore architectures allow the execution of mixed workloads where multiple parallel applications run concurrently competing on shared computational resources. As different applications exhibit different and time varying resources needs, a suitable allocation policy is required to properly select and map resources at run-time on demanding applications. We demonstrate how a user-space run-time resource manager could be extended to easily take advantage of performance counters in order to optimize both workloads execution time and energy consumption. Our approach, initially evaluated on a quad-core Intel machine considering a representative set of mixed-workloads from a standard benchmark suite, attains a 49,9{\%} mean energy-delay- product (EDP) speed-up over the standard Linux case, and a 13.4{\%} EDP speed-up over our previous work. Copyright {\&}copy; 2014 ACM.},
author = {Libutti, Simone and Massari, Giuseppe and Bellasi, Patrick and Fornaciari, William},
doi = {10.1145/2556863.2556866},
file = {:home/fifi/inria/these/biblio/2014 Libutti.pdf:pdf},
isbn = {9781450326070},
journal = {ACM International Conference Proceeding Series},
keywords = {Computer operating systems;Embedded systems;Energy},
pages = {27--32},
title = {{Exploiting performance counters for energy efficient co-scheduling of mixed workloads on multi-core platforms}},
url = {http://dx.doi.org/10.1145/2556863.2556866},
year = {2014}
}
@inproceedings{Hackenberg2015,
abstract = {The recently introduced Intel Xeon E5-1600 v3 and E5-2600 v3 series processors -- codenamed Haswell-EP -- implement major changes compared to their predecessors. Among these changes are integrated voltage regulators that enable individual voltages and frequencies for every core. In this paper we analyze a number of consequences of this development that are of utmost importance for energy efficiency optimization strategies such as dynamic voltage and frequency scaling (DVFS) and dynamic concurrency throttling (DCT). This includes the enhanced RAPL implementation and its improved accuracy as it moves from modeling to actual measurement. Another fundamental change is that every clock speed above AVX frequency -- including nominal frequency -- is opportunistic and unreliable, which vastly decreases performance predictability with potential effects on scalability. Moreover, we characterize significantly changed p-state transition behavior, and determine crucial memory performance data.},
annote = {NULL},
author = {Hackenberg, Daniel and Schone, Robert and Ilsche, Thomas and Molka, Daniel and Schuchart, Joseph and Geyer, Robin},
booktitle = {2015 IEEE International Parallel and Distributed Processing Symposium Workshop},
doi = {10.1109/IPDPSW.2015.70},
file = {:home/fifi/inria/these/biblio/2015 IEEE International Parallel and Distributed Processing Symposium Workshop (IPDPSW) 2015 Hackenberg.pdf:pdf},
isbn = {978-1-4673-7684-6},
keywords = {Benchmark testing,Energy measurement,Frequency measurement,Power demand,Random access memory,Regulators,Voltage control},
month = {may},
pages = {896--904},
publisher = {IEEE},
title = {{An Energy Efficiency Feature Survey of the Intel Haswell Processor}},
url = {http://ieeexplore.ieee.org/document/7284406/},
year = {2015}
}
@article{Davidovic2015,
abstract = {{\textcopyright} 2015 SCPE.The increasing energy consumption of large-scale high performance resources raises technical and economical concerns. A reduction of consumed energy in multicore systems is possible to some extent with an optimized usage of computing and memory resources that is tailored to specific HPC applications. The essential step towards more sustainable consumption of energy is its reliable measurements for each component of the system and selection of optimally configured resources for specific applications. This paper briefly surveys the current approaches for measuring and profiling power consumption in large scale systems. Then, a practical case study of a real-time power measurement of multicore computing system is presented on two real HPC applications: maximum clique algorithm and numerical weather prediction model. We assume that the computing resources are allocated in a HPC cloud on a pay-per-use basis. The measurements demonstrate that the minimal energy is consumed when all available cores (up to the scaling limit for a particular application) are used on their maximal frequencies and with threads binded to the cores.},
annote = {NULL},
author = {Davidovi{\'{c}}, Davor and Depolli, Matja{\v{z}} and Lipi{\'{c}}, Tomislav and Skala, Karolj and Trobec, Roman},
doi = {10.12694/scpe.v16i4.1132},
file = {:home/fifi/inria/these/biblio/Scalable Computing Practice and Experience 2016 Davidovic.pdf:pdf},
issn = {18951767},
journal = {Scalable Computing},
keywords = {Energy efficiency,High-performance,Maximum clique,Numerical weather prediction},
number = {4},
pages = {437--448},
title = {{Energy efficiency of parallel multicore programs}},
volume = {16},
year = {2015}
}

@inproceedings{Weng2002,
 author = {Weng, Tien-hsiung and Chapman, Barbara M.},
 title = {Implementing OpenMP Using Dataflow Execution Model for Data Locality and Efficient Parallel Execution},
 booktitle = {Proceedings of the 16th International Parallel and Distributed Processing Symposium},
 series = {IPDPS '02},
 year = {2002},
 isbn = {0-7695-1573-8},
 pages = {180--},
 url = {http://dl.acm.org/citation.cfm?id=645610.661369},
 acmid = {661369},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
} 
@article{Wienke2012,
author = {Wienke, Sandra and Springer, Paul and Terboven, Christian and an Mey, Dieter},
doi = {10.1007/978-3-642-32820-6},
file = {:home/fifi/inria/these/biblio/TaskParallelProgrammingOnNumaArchitectures (1).pdf:pdf},
isbn = {978-3-642-32819-0},
keywords = {233783944,accull,an openacc implementation with,and author profiles for,august 2012,conference paper,cuda and opencl support,discussions,https,net,publication,researchgate,stats,this publication at,www},
number = {February 2016},
pages = {859--870},
title = {{Task-Parallel Programming on NUMA Architectures}},
url = {http://dl.acm.org/citation.cfm?id=2402420.2402522},
volume = {7484},
year = {2012}
}

@article{Nanjegowda2009,
abstract = {OpenMP relies heavily on barrier synchronization to coordinate the work of threads that are performing the computations in$\backslash$na parallel region. A good implementation of barriers is thus an important part of any implementation of this API. As the numberof cores in shared and distributed shared memory machines continues to grow, the quality of the barrier implementation iscritical for application scalability. There are a number of known algorithms for providing barriers in software. In this paper,we consider some of the most widely used approaches for implementing barriers on large-scale shared-memory multiprocessorsystems: a ”blocking” implementation that de-schedules a waiting thread, a ”centralized” busy wait and three forms of distributed”busy” wait implementations are discussed. We have implemented the barrier algorithms in the runtime library associated witha research compiler, OpenUH. We first compare the impact of these algorithms on the overheads incurred for OpenMP constructsthat involve a barrier, possibly implicitly. We then show how the different barrier implementations influence the performanceof two different OpenMP application codes.},
author = {Nanjegowda, Ramachandra and Hernandez, Oscar and Chapman, Barbara and Jin, Haoqiang H.},
doi = {10.1007/978-3-642-02303-3_4},
file = {:home/fifi/inria/these/biblio/chapman{\_}barrier{\_}eval{\_}2009.pdf:pdf},
isbn = {3642022847},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {42--52},
title = {{Scalability evaluation of barrier algorithms for OpenMP}},
volume = {5568 LNCS},
year = {2009}
}

@article{Reinman2015,
author = {Reinman, Mickael},
file = {:home/fifi/inria/these/biblio/numa-aware-schedulin-rainman.pdf:pdf},
title = {{NUMA-aware scheduling for both memory- and compute-bound tasks}},
year = {2015}
}

@article{Zhuravlev2012,
abstract = {Chip multicore processors (CMPs) have emerged as the dominant architecture choice for modern computing platforms and will most likely continue to be dominant well into the foreseeable future. As with any system, CMPs offer a unique set of challenges. Chief among them is the shared resource contention that results because CMP cores are not independent processors but rather share common resources among cores such as the last level cache (LLC). Shared resource contention can lead to severe and unpredictable performance impact on the threads running on the CMP. Conversely, CMPs offer tremendous opportunities for mulithreaded applications, which can take advantage of simultaneous thread execution as well as fast inter thread data sharing. Many solutions have been proposed to deal with the negative aspects of CMPs and take advantage of the positive. This survey focuses on the subset of these solutions that exclusively make use of OS thread-level scheduling to achieve their goals. These solutions are particularly attractive as they require no changes to hardware and minimal or no changes to the OS. The OS scheduler has expanded well beyond its original role of time-multiplexing threads on a single core into a complex and effective resource manager. This article surveys a multitude of new and exciting work that explores the diverse new roles the OS scheduler can successfully take on.},
author = {Zhuravlev, Sergey and Saez, Juan Carlos and Blagodurov, Sergey and Fedorova, Alexandra and Prieto, Manuel},
doi = {10.1145/2379776.2379780},
file = {:home/fifi/inria/these/biblio/ACM Comput. Surv. 2012 Zhuravlev.pdf:pdf},
isbn = {2008005089},
issn = {03600300},
journal = {ACM Computing Surveys},
number = {1},
pages = {1--32},
title = {{Survey of Scheduling Techniques for Addressing Shared Resources in Multicore Processors}},
volume = {45},
year = {2012}
}
@article{Olivier2013,
abstract = {Task parallelism raises the level of abstraction in shared memory parallel programming to simplify the develop- ment of complex applications. However, task parallel applications can exhibit poor performance due to thread idleness, scheduling overheads, and work time inflation – additional time spent by threads in a multithreaded computation beyond the time required to perform the same work in a sequential computation. We identify the contributions of each factor to lost efficiency in various task parallel OpenMP applications and diagnose the causes of work time inflation in those applications. Increased data access latency can cause significant work time inflation in NUMA systems. Our locality framework for task parallel OpenMP programs mitigates this cause of work time inflation. Our extensions to the Qthreads library demonstrate that locality-aware scheduling can improve performance up to 3X compared to the Intel OpenMP task scheduler.},
author = {Olivier, Stephen L. and {De Supinski}, Bronis R. and Schulz, Martin and Prins, Jan F.},
doi = {10.3233/SPR-130369},
file = {:home/fifi/inria/these/biblio/898597.pdf:pdf},
isbn = {9781467308069},
issn = {10589244},
journal = {Scientific Programming},
keywords = {NUMA,OpenMP,Task parallel programming,affinity,locality,task scheduling},
number = {3-4},
pages = {123--136},
title = {{Characterizing and mitigating work time inflation in task parallel programs}},
volume = {21},
year = {2013}
}
@inproceedings{Pan2014, 
author={X. Pan and B. Jonsson}, 
booktitle={2014 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)}, 
title={Modeling cache coherence misses on multicores}, 
year={2014}, 
pages={96-105}, 
keywords={cache storage;data handling;multiprocessing systems;protocols;PARSEC benchmark suite;cache coherence misses;cache performance improvement;core data reuse patterns;data access pattern;intercore data sharing patterns;invalidation-based cache coherence protocols;multicore system;phased performance models;private cache coherency;program optimization;symmetric performance models;uniform performance models;Benchmark testing;Coherence;Data models;Instruction sets;Multicore processing;Predictive models;Protocols}, 
doi={10.1109/ISPASS.2014.6844465}, 
month={March},}

@article{Al-Omairy2015,
abstract = {We employ the dynamic runtime system OmpSs to decrease the overhead of data motion in the now ubiquitous non-uniform memory access (NUMA) high concurrency environment of multicore processors. The dense numerical linear algebra algorithms of Cholesky factorization and symmetric matrix inversion are employed as representative benchmarks. Work stealing occurs within an innovative NUMA-aware scheduling policy to reduce data movement between NUMA nodes. The overall approach achieves separation of concerns by abstracting the complexity of the hardware from the end users so that high productivity can be achieved. Performance results on a large NUMA system outperform the state-of-the-art existing implementations up to a two fold speedup for the Cholesky factorization, as well as the symmetric matrix inversion, while the OmpSs-enabled code maintains strong similarity to its original sequential version.},
author = {Al-Omairy, Rabab and Miranda, Guillermo and Ltaief, Hatem and Badia, Rosa M. and Martorell, Xavier and Labarta, Jesus and Keyes, David},
doi = {10.14529/jsfi150103},
file = {:home/fifi/inria/these/biblio/papier{\_}journal{\_}numa{\_}barcelone.pdf:pdf},
issn = {23138734},
journal = {Supercomputing Frontiers and Innovations},
keywords = {data locality,dense matrix computations,dynamic runtime systems,high performance computing,non-uniform memory access,software productivity,work stealing},
number = {1},
pages = {49--72},
title = {{Dense Matrix Computations on NUMA Architectures with Distance-Aware Work Stealing}},
url = {http://superfri.org/superfri/article/view/49},
volume = {2},
year = {2015}
}
@article{Gajinov2014,
author = {Gajinov, Vladimir and Stipi{\'{c}}, Sr{\&}{\#}273;an and Eri{\'{c}}, Igor and Unsal, Osman S and Ayguad{\'{e}}, Eduard and Cristal, Adri{\'{a}}n},
doi = {10.1145/2597917.2597942},
file = {:home/fifi/inria/these/biblio/gajinov2014{\_}dash{\_}bsc.pdf:pdf},
isbn = {978-1-4503-2870-8},
journal = {Proceedings of the 11th ACM Conference on Computing Frontiers},
keywords = {dataflow,shared memory,transactional memory},
pages = {4:1----4:11},
title = {{DaSH: A Benchmark Suite for Hybrid Dataflow and Shared Memory Programming Models: with Comparative Evaluation of Three Hybrid Dataflow Models}},
url = {http://doi.acm.org/10.1145/2597917.2597942},
year = {2014}
}
@article{Drebes2014,
author = {Drebes, Andi and Heydemann, Karine and Drach, Nathalie and Pop, Antoniu and Cohen, Albert},
doi = {10.1145/2641764},
file = {:home/fifi/inria/these/biblio/drebes2014.pdf:pdf},
isbn = {1544-3566},
issn = {15443566},
journal = {ACM Transactions on Architecture and Code Optimization},
number = {3},
pages = {1--25},
title = {{Topology-Aware and Dependence-Aware Scheduling and Memory Allocation for Task-Parallel Languages}},
url = {http://dl.acm.org/citation.cfm?doid=2658949.2641764},
volume = {11},
year = {2014}
}
//TODO
@article{Figueira2005,
abstract = {Hypercube structures are heavily used by parallel algorithms that require all-to-all communication. When communicating over a heterogeneous and irregular network, the performance obtained by the hypercube structure will depend on the matching of the hypercube structure to the topology of the underlying network. In this paper, we present strategies to build topology-based hypercubes structures. These strategies do not assume any kind of topology. They take into account the communication cost between pair of nodes to provide a performance-efficient hypercube structure. These enhanced hypercube structures help improve the performance of parallel applications that require all-to-all communication in heterogeneous networks by up to ∼30{\%}. {\textcopyright} Springer-Verlag Berlin Heidelberg 2005.},
author = {Figueira, S.M. and Reddi, V.J.},
file = {:home/fifi/inria/these/biblio/hypercube{\_}topo.pdf:pdf},
issn = {03029743},
journal = {Lecture Notes in Computer Science},
pages = {994--1004},
title = {{Topology-based hypercube structures for global communication in heterogeneous networks}},
volume = {3648},
year = {2005}
}
//TODO
@article{Nanjegowda2009a,
abstract = {OpenMP relies heavily on barrier synchronization to coordinate the work of threads that are performing the computations in$\backslash$na parallel region. A good implementation of barriers is thus an important part of any implementation of this API. As the numberof cores in shared and distributed shared memory machines continues to grow, the quality of the barrier implementation iscritical for application scalability. There are a number of known algorithms for providing barriers in software. In this paper,we consider some of the most widely used approaches for implementing barriers on large-scale shared-memory multiprocessorsystems: a ”blocking” implementation that de-schedules a waiting thread, a ”centralized” busy wait and three forms of distributed”busy” wait implementations are discussed. We have implemented the barrier algorithms in the runtime library associated witha research compiler, OpenUH. We first compare the impact of these algorithms on the overheads incurred for OpenMP constructsthat involve a barrier, possibly implicitly. We then show how the different barrier implementations influence the performanceof two different OpenMP application codes.},
author = {Nanjegowda, Ramachandra and Hernandez, Oscar and Chapman, Barbara and Jin, Haoqiang H.},
doi = {10.1007/978-3-642-02303-3_4},
file = {:home/fifi/inria/these/biblio/scalability-Nanjegowda.pdf:pdf},
isbn = {3642022847},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {42--52},
title = {{Scalability evaluation of barrier algorithms for OpenMP}},
volume = {5568 LNCS},
year = {2009}
}

@article{Bao2016,
 author = {Bao, Wenlei and Hong, Changwan and Chunduri, Sudheer and Krishnamoorthy, Sriram and Pouchet, Louis-No\"{e}l and Rastello, Fabrice and Sadayappan, P.},
 title = {Static and Dynamic Frequency Scaling on Multicore CPUs},
 journal = {ACM Trans. Archit. Code Optim.},
 issue_date = {December 2016},
 volume = {13},
 number = {4},
 month = dec,
 year = {2016},
 issn = {1544-3566},
 pages = {51:1--51:26},
 articleno = {51},
 numpages = {26},
 url = {http://doi.acm.org/10.1145/3011017},
 doi = {10.1145/3011017},
 acmid = {3011017},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Affine Programs, CPU Energy, Static Analysis, Voltage and Frequency Scaling},
} 

//TODO
@article{Bramas2016,
abstract = {La méthode des éléments frontières pour l'équation des ondes (BEM) est utilisée en acoustique et en électromagnétisme pour simuler la propagation d'une onde avec une discrétisation en temps (TD). Elle permet d'obtenir un résultat pour plusieurs fréquences à partir d'une seule résolution. Dans cette thèse, nous nous intéressons à l'implémentation efficace d'un simulateur TD-BEM sous différents angles. Nous décrivons le contexte de notre étude et la formulation utilisée qui s'exprime sous la forme d'un système linéaire composé de plusieurs matrices d'interactions/convolutions. Ce système est naturellement calculé en utilisant l'opérateur matrice/vecteur creux (SpMV). Nous avons travaillé sur la limite du SpMV en étudiant la permutation des matrices et le comportement de notre implémentation aidé par la vectorisation sur CPU et avec une approche par bloc sur GPU. Nous montrons que cet opérateur n'est pas approprié pour notre problème et nous pro- posons de changer l'ordre de calcul afin d'obtenir une matrice avec une structure particulière. Cette nouvelle structure est appelée une matrice tranche et se calcule à l'aide d'un opérateur spé- cifique. Nous décrivons des implémentations optimisées sur architectures modernes du calcul haute-performance. Le simulateur résultant est parallélisé avec une approche hybride (mémoires partagées/distribuées) sur des n{\oe}uds hétérogènes, et se base sur une nouvelle heuristique pour équilibrer le travail entre les processeurs. Cette approche matricielle a une complexité quadratique si bien que nous avons étudié son accélération par la méthode des multipoles rapides (FMM). Nous avons tout d'abord travaillé sur la parallélisation de l'algorithme de la FMM en utilisant différents paradigmes et nous montrons comment les moteurs d'exécution sont adaptés pour relâcher le po- tentiel de la FMM. Enfin, nous présentons des résultats préliminaires d'un simulateur TD-BEM accéléré par FMM .},
author = {Bramas, Berenger},
file = {:home/fifi/inria/these/biblio/BRAMAS{\_}BERENGER{\_}2016.pdf:pdf},
keywords = {GPU,acoustique,calcul haute performance,électromagnétisme.,équation des ondes,méthode des éléments frontières,optimisation,programmation parallèle,vectorisation},
title = {{Optimization and parallelization of the boundary element method for the wave equation in time domain}},
url = {https://hal.inria.fr/tel-01306571},
year = {2016}
}
//TODO
@article{Nanjegowda2009b,
abstract = {OpenMP relies heavily on barrier synchronization to coordinate the work of threads that are performing the computations in$\backslash$na parallel region. A good implementation of barriers is thus an important part of any implementation of this API. As the numberof cores in shared and distributed shared memory machines continues to grow, the quality of the barrier implementation iscritical for application scalability. There are a number of known algorithms for providing barriers in software. In this paper,we consider some of the most widely used approaches for implementing barriers on large-scale shared-memory multiprocessorsystems: a ”blocking” implementation that de-schedules a waiting thread, a ”centralized” busy wait and three forms of distributed”busy” wait implementations are discussed. We have implemented the barrier algorithms in the runtime library associated witha research compiler, OpenUH. We first compare the impact of these algorithms on the overheads incurred for OpenMP constructsthat involve a barrier, possibly implicitly. We then show how the different barrier implementations influence the performanceof two different OpenMP application codes.},
author = {Nanjegowda, Ramachandra and Hernandez, Oscar and Chapman, Barbara and Jin, Haoqiang H.},
doi = {10.1007/978-3-642-02303-3_4},
file = {:home/fifi/inria/these/biblio/scalability-Nanjegowda.pdf:pdf;:home/fifi/inria/these/biblio/chapman{\_}barrier{\_}eval{\_}2009.pdf:pdf},
isbn = {3642022847},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {42--52},
title = {{Scalability evaluation of barrier algorithms for OpenMP}},
volume = {5568 LNCS},
year = {2009}
}
@article{Dice2013,
author = {Dice, Dave and Lev, Yossi and Moir, Mark},
doi = {10.1145/2442516.2442558},
file = {:home/fifi/inria/these/biblio/scalable{\_}statistic{\_}perfcounters.pdf:pdf},
isbn = {9781450319225},
issn = {15232867},
journal = {Proceedings of the 18th ACM SIGPLAN symposium on Principles and practice of parallel programming - PPoPP '13},
keywords = {accuracy,performance,scalability,statistical counters},
pages = {307},
title = {{Scalable statistics counters}},
url = {http://dl.acm.org/citation.cfm?doid=2442516.2442558},
year = {2013}
}
@article{Selva2015,
author = {Selva, Manuel},
file = {:home/fifi/inria/these/biblio/Manuel-Selva-Thesis.pdf:pdf},
title = {{Performance Monitoring of Throughput Constrained Dataflow Programs Executed On Shared-Memory Multi-core Architectures}},
year = {2015}
}
@article{Li2013,
abstract = {Data-intensive applications frequently rely on multicore computer systems, in which Non-Uniform Memory Access (NUMA) is a dominant architecture. To transfer data into and out from these high-performance computers becomes a bottleneck, and thus it is crucial to understand their I/O performance characteristics. However, the complexity in NUMA architecture presents a new challenge in modeling its I/O access cost, and thus lead to difficulties in configuring proper processor and memory affinity. In this paper, we show that existing NUMA experimental methods and metrics are inappropriate on contemporary high-end systems. We characterize a state-of-the-art NUMA host, and propose, to the best of our knowledge, the first methodology to simulate I/O operations using memory semantics, and model the I/O bandwidth performance. Our methodology is thoroughly tested and validated by mapping multiple parallel I/O streams to different sets of hardware components (CPU, memory, network cards, and SSDs) and by measuring the performance of each mapping. The experimental results and analysis reveal that our methodology can dramatically reduce characterization workload, accurately estimate the overall I/O performance, and effectively mitigate resource contention among I/O tasks.},
author = {Li, Tan and Ren, Yufei and Yu, Dantong and Jin, Shudong and Robertazzi, Thomas},
doi = {10.1109/ICPP.2013.46},
file = {:home/fifi/inria/these/biblio/numa{\_}characterization{\_}icpp13.pdf:pdf},
isbn = {9780769551173},
issn = {01903918},
journal = {Proceedings of the International Conference on Parallel Processing},
keywords = {Data transfer,Input/output(I/O),NUMA effects,Performance model},
pages = {369--378},
title = {{Characterization of Input/Output bandwidth performance models in NUMA architecture for data intensive applications}},
year = {2013}
}
@inproceedings{Sbirlea2015,
 author = {Sb\^{\i}rlea, Alina and Shirako, Jun and Pouchet, Louis-No\"{e}l and Sarkar, Vivek},
 title = {Polyhedral Optimizations for a Data-Flow Graph Language},
 booktitle = {Revised Selected Papers of the 28th International Workshop on Languages and Compilers for Parallel Computing - Volume 9519},
 series = {LCPC 2015},
 year = {2016},
 isbn = {978-3-319-29777-4},
 location = {Raleigh, NC, USA},
 pages = {57--72},
 numpages = {16},
 url = {http://dx.doi.org/10.1007/978-3-319-29778-1_4},
 doi = {10.1007/978-3-319-29778-1_4},
 acmid = {2958406},
 publisher = {Springer-Verlag New York, Inc.},
 address = {New York, NY, USA},
} 

@article{Nikolopoulos2001,
 author = {Nikolopoulos, D. S. and Artiaga, E. and Ayguad{\'e}, E. and Labarta, J.},
 title = {Exploiting Memory Affinity in OpenMP Through Schedule Reuse},
 journal = {SIGARCH Comput. Archit. News},
 issue_date = {December 2001},
 volume = {29},
 number = {5},
 month = dec,
 year = {2001},
 issn = {0163-5964},
 pages = {49--55},
 numpages = {7},
 url = {http://doi.acm.org/10.1145/563647.563657},
 doi = {10.1145/563647.563657},
 acmid = {563657},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {OpenMP, computation affinity, data, page placement, shared-memory programming models},
}

@inproceedings{Dobson2003,
 author = {Dobson, M. and Gaughen, P. and Hohnbaum, M. and Focht, E.},
 title = {Linux Support for NUMA Hardware},
 booktitle = {Ottawa Linux Symposium 2003},
 year = {2003},
}

@book{Reinders2007,
 author = {Reinders, James},
 title = {Intel Threading Building Blocks},
 year = {2007},
 isbn = {9780596514808},
 edition = {First},
 publisher = {O'Reilly \& Associates, Inc.},
 address = {Sebastopol, CA, USA},
}
@INPROCEEDINGS{Kedzierski2010, 
  author={K. Kędzierski and M. Moreto and F. J. Cazorla and M. Valero}, 
  booktitle={2010 IEEE International Symposium on Parallel Distributed Processing (IPDPS)}, 
  title={Adapting cache partitioning algorithms to pseudo-LRU replacement policies}, 
  year={2010}, 
  volume={}, 
  number={}, 
  pages={1-12}, 
  keywords={cache storage;multiprocessing systems;quality of service;CMP processors;IBM;QoS;Sun Microsystems;binary tree;cache partitioning algorithms;complete partitioning system;hardware complexity;hardware techniques;least recently used replacement policy;not recently used;profiling logic;pseudo-LRU replacement policies;quality of service;Binary trees;Costs;Degradation;Hardware;Logic;Partitioning algorithms;Proposals;Quality of service;Sun;Throughput;CMP;Pseudo-LRU;Shared last level cache}, 
  doi={10.1109/IPDPS.2010.5470352}, 
  ISSN={1530-2075}, 
  month={April},
}

@inproceedings{Al-Zoubi2004,
 author = {Al-Zoubi, Hussein and Milenkovic, Aleksandar and Milenkovic, Milena},
 title = {Performance Evaluation of Cache Replacement Policies for the SPEC CPU2000 Benchmark Suite},
 booktitle = {Proceedings of the 42Nd Annual Southeast Regional Conference},
 series = {ACM-SE 42},
 year = {2004},
 isbn = {1-58113-870-9},
 location = {Huntsville, Alabama},
 pages = {267--272},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/986537.986601},
 doi = {10.1145/986537.986601},
 acmid = {986601},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {cache memory, performance evaluation, replacement policy},
} 

@misc{numactl,
  author = {Kleen, A.},
  title = {A NUMA API for Linux.},
  url = {http://halobates.de/numaapi3.pdf},
  year = {2004},
}

@inproceedings{Karp1992,
 author = {Karp, Richard M.},
 title = {On-Line Algorithms Versus Off-Line Algorithms: How Much is It Worth to Know the Future?},
 booktitle = {Proceedings of the IFIP 12th World Computer Congress on Algorithms, Software, Architecture - Information Processing '92, Volume 1 - Volume I},
 year = {1992},
 isbn = {0-444-89747-X},
 pages = {416--429},
 numpages = {14},
 url = {http://www.icsi.berkeley.edu/pubs/techreports/TR-92-044.pdf},
 acmid = {659725},
 publisher = {North-Holland Publishing Co.},
 address = {Amsterdam, The Netherlands, The Netherlands},
}

@ARTICLE{HEFT, 
author={H. Topcuoglu and S. Hariri and Min-You Wu}, 
journal={IEEE Transactions on Parallel and Distributed Systems}, 
title={Performance-effective and low-complexity task scheduling for heterogeneous computing}, 
year={2002}, 
volume={13}, 
number={3}, 
pages={260-274}, 
keywords={directed graphs;processor scheduling;workstation clusters;Critical-Path-on-a-Processor algorithm;DAG scheduling;Heterogeneous Earliest-Finish-Time algorithm;application scheduling problem;heterogeneous computing environments;list scheduling;parametric graph generator;scheduling costs;task graphs;time metrics;weighted directed acyclic graphs;Processor scheduling}, 
doi={10.1109/71.993206}, 
ISSN={1045-9219}, 
month={Mar},
}

@article{Locke1992,
author = {Locke, C Douglass},
doi = {10.1007/BF00365463},
issn = {1573-1383},
journal = {Real-Time Systems},
month = {mar},
number = {1},
pages = {37--53},
title = {{Software architecture for hard real-time applications: Cyclic executives vs. fixed priority executives}},
url = {https://doi.org/10.1007/BF00365463},
volume = {4},
year = {1992}
}

@inproceedings{Cook1971,
 author = {Cook, Stephen A.},
 title = {The Complexity of Theorem-proving Procedures},
 booktitle = {Proceedings of the Third Annual ACM Symposium on Theory of Computing},
 series = {STOC '71},
 year = {1971},
 location = {Shaker Heights, Ohio, USA},
 pages = {151--158},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/800157.805047},
 doi = {10.1145/800157.805047},
 acmid = {805047},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@ARTICLE{Yang1994, 
author={Tao Yang and A. Gerasoulis}, 
journal={IEEE Transactions on Parallel and Distributed Systems}, 
title={DSC: scheduling parallel tasks on an unbounded number of processors}, 
year={1994}, 
volume={5}, 
number={9}, 
pages={951-967}, 
keywords={computational complexity;directed graphs;parallel algorithms;parallel programming;scheduling;trees (mathematics);DAGs;DSC;ETF;MD;NP-complete;arbitrary directed acyclic task graphs;coarse-grain trees;completely connected processor;dominant sequence clustering algorithm;fine-grain trees;fork;general scheduling algorithms;join;low-complexity heuristic;nonzero communication overhead;optimal schedules;parallel task scheduling;performance;special classes;unbounded number;Clustering algorithms;Computer science;Multiprocessor interconnection networks;Network topology;Optimal scheduling;Parallel processing;Processor scheduling;Program processors;Scheduling algorithm;Tree graphs}, 
doi={10.1109/71.308533}, 
ISSN={1045-9219}, 
month={Sep},
}

@inproceedings{Barthou2014,
  TITLE = {{SPAGHETtI: Scheduling/Placement Approach for Task-Graphs on HETerogeneous archItecture}},
  AUTHOR = {Barthou, Denis and Jeannot, Emmanuel},
  URL = {https://hal.archives-ouvertes.fr/hal-01100948},
  BOOKTITLE = {{Euro-Par}},
  ADDRESS = {Lisboa, Portugal},
  SERIES = {LNCS},
  VOLUME = {8632},
  PAGES = {174 - 185},
  YEAR = {2014},
  MONTH = Aug,
  DOI = {10.1007/978-3-319-09873-9\_15},
  PDF = {https://hal.archives-ouvertes.fr/hal-01100948/file/barthou_jeannot.pdf},
  HAL_ID = {hal-01100948},
  HAL_VERSION = {v1},
}

@article{Stone2010,
 author = {Stone, John E. and Gohara, David and Shi, Guochun},
 title = {OpenCL: A Parallel Programming Standard for Heterogeneous Computing Systems},
 journal = {IEEE Des. Test},
 issue_date = {May 2010},
 volume = {12},
 number = {3},
 month = may,
 year = {2010},
 issn = {0740-7475},
 pages = {66--73},
 numpages = {8},
 url = {http://dx.doi.org/10.1109/MCSE.2010.69},
 doi = {10.1109/MCSE.2010.69},
 acmid = {1803953},
 publisher = {IEEE Computer Society Press},
 address = {Los Alamitos, CA, USA},
} 

@phdthesis{Bienia2011,
 author = {Bienia, Christian},
 advisor = {Li, Kai},
 title = {Benchmarking Modern Multiprocessors},
 year = {2011},
 isbn = {978-1-124-49186-8},
 note = {AAI3445564},
 publisher = {Princeton University},
 address = {Princeton, NJ, USA},
} 

@inproceedings{Jaleel2010,
 author = {Jaleel, Aamer and Theobald, Kevin B. and Steely,Jr., Simon C. and Emer, Joel},
 title = {High Performance Cache Replacement Using Re-reference Interval Prediction (RRIP)},
 booktitle = {Proceedings of the 37th Annual International Symposium on Computer Architecture},
 series = {ISCA '10},
 year = {2010},
 isbn = {978-1-4503-0053-7},
 location = {Saint-Malo, France},
 pages = {60--71},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/1815961.1815971},
 doi = {10.1145/1815961.1815971},
 acmid = {1815971},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {replacement, scan resistance, shared cache, thrashing},
}

@book{Jeffers2016,
 author = {Jeffers, James and Reinders, James and Sodani, Avinash},
 title = {Intel Xeon Phi Processor High Performance Programming: Knights Landing Edition 2Nd Edition},
 year = {2016},
 isbn = {0128091940, 9780128091944},
 edition = {2nd},
 pages = {545},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
} 

@article{Blumofe1999,
 author = {Blumofe, Robert D. and Leiserson, Charles E.},
 title = {Scheduling Multithreaded Computations by Work Stealing},
 journal = {J. ACM},
 issue_date = {Sept. 1999},
 volume = {46},
 number = {5},
 month = sep,
 year = {1999},
 issn = {0004-5411},
 pages = {720--748},
 numpages = {29},
 url = {http://doi.acm.org/10.1145/324133.324234},
 doi = {10.1145/324133.324234},
 acmid = {324234},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {critical-path length, multiprocessor, multithreading, randomized algorithm, thread scheduling, work stealing},
}

@INPROCEEDINGS{Pousa2009, 
author={C. P. Ribeiro and J. F. Mehaut and A. Carissimi and M. Castro and L. G. Fernandes},
booktitle={2009 21st International Symposium on Computer Architecture and High Performance Computing},
title={Memory Affinity for Hierarchical Shared Memory Multiprocessors},
year={2009},
volume={},
number={},
pages={59-66},
keywords={Linux;application program interfaces;distributed shared memory systems;optimisation;software performance evaluation;storage management;Linux;NAS parallel benchmarks;cache-coherent NUMA platform;data distribution;data placement;fine data control;flexibility;geophysics application;hierarchical shared memory multiprocessors;high performance computing;memory access constraints;memory affinity control;memory affinity interface;non-uniform memory access;numerical scientific data;parallel platforms;portability;user level interface;Computer architecture;Data structures;Geophysics;High performance computing;Laboratories;Large-scale systems;Linux;Memory management;Multiprocessing systems;Yarn;ICTM;MAi;Memory Affinity;NAS;NUMA},
doi={10.1109/SBAC-PAD.2009.16},
ISSN={1550-6533},
month={Oct},
}

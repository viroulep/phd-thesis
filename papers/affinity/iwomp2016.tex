\documentclass{Styles/llncs}
%\documentclass[12pt,letterpaper]{article}
\usepackage{times}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{url}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{subfig}
\usepackage{wrapfig}
\usepackage{multirow}
\usepackage{boxedminipage}
\usepackage{xspace}
\usepackage{listings}
\usepackage{listingsutf8}
\usepackage{verbatim}
\usepackage{parcolumns}
\usepackage{color}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
%Prevents floating item to "jump" between sections
\usepackage[section]{placeins}
\usepackage{booktabs}
\newcommand{\arevoir}[1]{#1}

\newcommand{\kaapi}{\textsc{\mbox{XKaapi}}\xspace}

\newcommand{\libXKOMP}{\textsc{libKOMP}\xspace}

\usepackage{xcolor}
\usepackage{todonotes}
\usepackage[color,leftbars]{changebar}

\newcommand{\cfsect}[1]{(\textit{cf.} section~\ref{#1})}
\newcommand{\cfsectpage}[1]{(\textit{cf.} section~\ref{#1}, page~\pageref{#1})}
\providecommand{\figureref}[1]{\figname~\ref{#1}}
\providecommand{\cftab}[1]{(\textit{cf.} tableau~\ref{#1})}
\newcommand{\cmd}[1]{{\upshape\texttt{\symbol{"5C}#1}}}

\newenvironment{remarque}
{\description \item[Remarque:] \ \slshape}
{\enddescription}

\makeatletter
\newbox\sf@box
\newenvironment{SubFloat}[2][]%
  {\def\sf@one{#1}%
   \def\sf@two{#2}%
   \setbox\sf@box\hbox
     \bgroup}%
  { \egroup
   \ifx\@empty\sf@two\@empty\relax
     \def\sf@two{\@empty}
   \fi
   \ifx\@empty\sf@one\@empty\relax
     \subfloat[\sf@two]{\box\sf@box}%
   \else
     \subfloat[\sf@one][\sf@two]{\box\sf@box}%
   \fi}
\makeatother
\renewcommand\floatpagefraction{.9}
\renewcommand\topfraction{.9}
\renewcommand\bottomfraction{.9}
\renewcommand\textfraction{.1}
\setcounter{totalnumber}{50}
\setcounter{topnumber}{50}
\setcounter{bottomnumber}{50}
\renewcommand{\ttdefault}{pcr}
\lstset{
	tabsize=4,
%	frame=single,
	breaklines=true,
	basicstyle=\ttfamily,
	frame=tb,
	framerule=0.2pt,
%	frameround={tttt},
	showstringspaces=false,
	language=c,
%	linewidth=0.95\textwidth,
	keywordstyle=\color{black}\bfseries,
%	keywordstyle=\color{blue},
	commentstyle=\color{OliveGreen},
	stringstyle=\color{red}\itshape,
	inputencoding=utf8/latin1,
	numbers=left,
	numberstyle=\tiny,
	numbersep=5pt,
% OMP define
emph={\#,pragma, taskwait, omp, task, depend}, emphstyle=\color{RoyalBlue}\bfseries,
emph={[2]in,inout,out,cw,data,numa,core}, emphstyle={[2]\color{BrickRed}\bfseries},
emph={[3]tied,untied,shared}, emphstyle={[3]\color{Gray}\bfseries},
emph={[4]lu0,fwd,bdiv,bmod}, emphstyle={[4]\color{DarkGreen}\bfseries},
emph={[5]affinity, omp_get_numa_num, omp_get_core_num, omp_get_num_cores, omp_get_num_numas, omp_get_numa_from_data}, emphstyle={[5]\color{DarkViolet}\bfseries},
    %moredelim=**[is][\only<3>{\color{red}}]{@}{@},
}
\lstdefinestyle{smaller}{basicstyle=\scriptsize\ttfamily}
\lstMakeShortInline|

\newcommand{\benchs}{KASTORS }

\sloppy

\begin{document}

\title{TODO}
\author{
  Philippe Virouleau \and François Broquedis \and Thierry Gautier \and Fabrice Rastello
 \vspace*{-1ex}}
\institute{
   Inria,
   Univ. Grenoble Alpes,  CNRS, Grenoble Institute of Technology, LIG, Grenoble, France
   LIP, ENS de Lyon, France\\
   \email{firstname.lastname@inria.fr}\\
   \email{thierry.gautier@inrialpes.fr}\\
}
\date{}
\maketitle

\begin{abstract}
  \vspace*{-5ex} TODO

\smallskip
  \noindent\textbf{Keywords:}
  \emph{
    OpenMP, task dependencies, affinity, runtime systems, NUMA
  }
\end{abstract}


\section{Introduction}

OpenMP has become a major standard to program parallel applications on a wide variety of parallel platforms ranging from desktop notebooks to high-end supercomputers. It provides keywords to express fine grain task-based parallelism that boost the applications performance and scalability on large scale shared memory machines. In particular, tasking in OpenMP helps the programmers parallelize applications with irregular workload, letting the runtime system in charge of performing load balancing through task scheduling in a dynamic way. However, very little support exists to express and to control the affinity between tasks and data on systems with a decentralized memory layout, like \emph{Non-Uniform Memory Architectures} (NUMA). On such systems, the memory is physically split into several banks, also called \emph{NUMA nodes}, which leads to different memory latencies and throughputs depending on the location of the memory bank a core is accessing data from. To get the most performance out of such architectures, OpenMP runtime systems thus need to be extended to make the task scheduler aware of both the underlying hardware and the relation that exists between a task and the data it accesses.
 
 We relate in this paper our experiences to reach high performance out of OpenMP numerical applications on 192-core NUMA machine. The recently-added \emph{places} concept in the OpenMP 4.0 specification provides ways of binding OpenMP parallel regions to user-defined partitions of the machine. This basically ends up binding the threads of the corresponding region to a set of cores. Thus, relying on the first-touch memory allocation policy as a portable solution to control memory binding, OpenMP places can help to control thread affinity with respect to the memory.
%Nevertheless, if this solution exists it remains cumbersome with inherent shortages: it does not ensure clarity in the program between computations and memory access; Design of library remains complex due to non-composable non functional properties; It does not provide robust solution when load is high unbalanced between threads of different parallel regions.
However, the concept behind OpenMP places needs to be extended to improve the performance of task-based applications, as tasks are most of the time scheduled over threads in a dynamic way according to a work-stealing execution model.  This is why the OpenMP \emph{Architecture Review Board} is currently discussing the introduction of a new \textit{affinity} feature to make the runtime system aware of the affinities between the tasks and the data they access. 

In this paper, we present how we control task and data placement inside our OpenMP runtime system, implementing an \emph{affinity} clause which syntax is very close to the one currently discussed by the ARB. We also explain how we manage such information at runtime in order to improve the execution of task-based OpenMP programs on NUMA systems, with a particular focus on the scheduling data structure and the scheduling algorithm. 

The contribution of this paper is threefold:
\begin{itemize}
\item We propose an OpenMP-friendly \emph{affinity} extension to the Clang-3.8 compiler able to express affinities between tasks and memory and pass this information along to the runtime system ;
\item We describe an extension to our task-based OpenMP runtime system to guide the scheduling of tasks according to such information to reach better performance on NUMA systems ;
\item We present some preliminary experimental results on running OpenMP benchmarks with tasks dependencies on a 192-core NUMA system, with and without using \emph{affinity}.
\end{itemize}

%Francois : je sais pas s'il faut le mettre dans l'intro ça.
%Some preliminary experimental results demonstrate the capacity to manage finer information such as handle by affinity of task and memory. By analyzing our experimental results, we note OpenMP depend tasks based programs, with assumption that all accessed memory regions are encoded in dependencies, can be automatically scheduled with the same level of performance without adding clause to specify affinity.

The remainder of this paper is organized as follows : blablabla.

\section{Motivation: examples where we need support}

TODO

- trouver une application qui nécessite cela, typiquement une application itérative type stencil
  -> done, jacobi, on peut comparer taskdep+affinity vs taskdep vs for, affini est meilleurs
  -> dpot, si le runtime peut être malin, c'est tout aussi simple que le programmeur indique explicitement quelle dépendance est "importante"
- une clause qui permet de contrôler l’affinité tâche / donnée ou tâche / ressources est importante pour les perf
- le comité discute de cela

\section{Contributions}

In this section, we describe the details of our propositions, starting with the
language extension description, followed by our runtime extensions we implemented
to take advantage of this information.



\subsection{Language extension}

We propose an extension to precisely control the \emph{affinity} of a task with a specific part of the architecture hierarchy.

The two main components of NUMA architectures are cores and nodes, and one of
the key to get performances out of NUMA architectures is to ensure tasks are
executing close to their data.
Therefore we identified three different kinds of \emph{affinity} the programmer
may need to express, which are the following:
\begin{itemize}
    \item A physical core.

      The runtime should try to schedule the task on the specified physical core.

    \item A NUMA node

      The runtime should try to schedule the task on any of the physical cores on
      the given NUMA node.

    \item A data

      The runtime should try to schedule the task on any of the physical cores on
      the NUMA node on which the given data has been physically allocated.
\end{itemize}

Additionally, the programmer can specify if this affinity is \emph{strict} (the task must be executed on the given resource), or not.

Since this extension is aimed for the tasking construct, we implemented it as a new
clause for the \emph{task} directive. The proposed syntax for the clause is the following:
FIXME: on renomme "depend" en "data" ?
\begin{lstlisting}
affinity([numa,core,data]: expr[, strict])
\end{lstlisting}

In order to dynamically get information about the current team hierarchy, we also propose
the following API functions:

\begin{lstlisting}
//Get the number of NUMA nodes in the team
omp_get_num_numas(void);
//Get the NUMA node the task is currently executed on
omp_get_numa_num(void);
//Get the NUMA node the data has been allocated on
omp_get_numa_from_data(void *data);
//FIXME: les deux appels suivant sont en fait get_num_threads etc
omp_get_num_cores(void);
omp_get_core_num(void);
\end{lstlisting}

We implemented these propositions in the Clang compiler, based on the 3.8 version\footnote{https://github.com/viroulep/clang}; and we also added the corresponding entry points in Clang's OpenMP runtime\footnote{https://github.com/viroulep/openmp}.


\subsection{Runtime extension}

We implemented extensions in the OpenMP runtime developed in our team, \libXKOMP~\cite{libkomp} (TODO cite),
which is based on the \kaapi~\cite{Bleuse2014} runtime system (TODO cite).

\kaapi is a task-based runtime system, using workstealing has a general scheduling strategy.
Here is a brief description of some of its key internal structures and machanisms.

\subsubsection{The way \kaapi models the architecture.}

\kaapi sees the architecture topology as a hierarchy of \verb/places/.
A \verb/place/ is a list of tasks associated with a subset of the machine processing units.
\kaapi's places are very similar to the notion of \emph{shepherd} introduced in \cite{DBLP:journals/ijhpca/OlivierPWSP12}, or ForestGOMP's \emph{runqueues}~\cite{BroFurGogWacNam10IJPP}.
\kaapi most of the time only considers two levels of places : node-level places,
which are bound to the set of processors contained in a NUMA node, and processor-level places, which are bound to a single processor of the platform.
This way, at the processor level one \verb/place/ is associated to each of the physical cores, and
at the NUMA node level one \verb/place/ is associated to each of the NUMA nodes.


\subsubsection{The way \kaapi enables ready tasks and steals them.}

The scheduling framework in \kaapi~\cite{Bleuse2014} relies on virtual functions
for \textit{selecting a victim} and \textit{selecting a place} to push a ready task.
When a processor becomes idle, the runtime system calls a function, called  \verb/WSselect/ for \emph{work-stealing select}, to browse the topology to find a place from which stealing a task from the place task queue.
%There are many ways to do so, implemented in different \emph{selection strategies} called \verb/WSselect/, for \emph{work-stealing select} in the remaining of the paper.
%Once a place is selected, the processor will take a ready task from its queue.

\subsubsection{Implementation of the affinity}

Before the creation of a task, if it has an affinity clause, an internal function
will be called to set the appropriate parameters in the ICVs.

During task creation, these parameters will be set in the task description.

When a task becomes ready to be executed, the function responsible for the \textit{selection of the place} to push
the task will look at the affinity and select the appropriate place.
\kaapi relies on the \verb/get_mempolicy/ function to identify the NUMA node on which a data is allocated.

As described earlier, an affinity can be \emph{strict} or not; to implement this we used
a private queue per place. If the affinity is strict, the task is pushed to the place's private queue.
During the \textit{victim selection}, a thread may only steal from the place's
public queue (in case of a place attached to a  NUMA node, every thread on this node can steal from the private queue).

\section{Usage example and experimentation results}

TODO Décrire les différentes variantes
(affinity, initialisation etc)

décrire choix des tailles+tailles de bloc

graph

conclusion: type d'application (stencil) très dépendant de la localisation de ses voisins
-> le côté strict permet de garantir que les tâches ne bougent pas
-> ne pas mettre d'affinité/d'initialisation implique que les tâches auront de gros temps d'accès à leurs données
-> régler le problème du block-for avec initialisation, si itérations dans le "bon" ordre ça se passe bien.

\section{Related work}

TODO


\section*{Acknowledgments}


This work is integrated and supported by the ELCI  project, a French FSN ("Fond pour la Société Numérique")
project that associates academic and industrial partners to design and provide software environment for very high performance
computing.
  \small \bibliographystyle{Styles/iplain}
%\nocite{*}
\bibliography{Bib/paper}

\end{document}
